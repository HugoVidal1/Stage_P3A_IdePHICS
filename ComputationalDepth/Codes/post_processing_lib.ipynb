{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "from matplotlib.ticker import LogLocator\n",
    "from matplotlib.lines import Line2D\n",
    "from copy import deepcopy\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "import time\n",
    "import gc\n",
    "import scipy\n",
    "from scipy.signal import butter, filtfilt, argrelextrema\n",
    "from scipy.interpolate import interp1d\n",
    "from mup import MuReadout, MuSGD, MuAdam\n",
    "import mup as mup\n",
    "from pathlib import Path\n",
    "\n",
    "device = 'mps'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Smoothing features #####\n",
    "def lower_envelope(x,y):\n",
    "    minima_idx = argrelextrema(y, np.less, order=1)[0]\n",
    "    x_sampled = x[minima_idx]\n",
    "    y = y[minima_idx]\n",
    "    interp = interp1d(x_sampled, y, kind='linear', fill_value='extrapolate')\n",
    "    y = interp(x)\n",
    "    return np.array([x, y]).transpose()\n",
    "\n",
    "def upper_envelope(x,y):\n",
    "    maxima_idx = argrelextrema(y, np.greater, order=2)[0]\n",
    "    x_sampled = x[maxima_idx]\n",
    "    y = y[maxima_idx]\n",
    "    interp = interp1d(x_sampled, y, kind='linear', fill_value='extrapolate')\n",
    "    y = interp(x)\n",
    "    return np.array([x, y]).transpose()\n",
    "\n",
    "def low_pass_filter(y, f_c, order = 5):\n",
    "    b, a = butter(order, f_c, btype='low')\n",
    "    return filtfilt(b,a,y)\n",
    "\n",
    "def moving_average(arr, window_size=20):\n",
    "    return np.convolve(arr, np.ones(window_size)/window_size, mode='valid')\n",
    "\n",
    "def smooth_xy_for_plot(x, y, window_size=1):\n",
    "    y_smooth = moving_average(y, window_size)\n",
    "    # Truncate x to match\n",
    "    x_smooth = x[:len(y_smooth)]\n",
    "    return np.column_stack([x_smooth, y_smooth])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Load a dictionnary of curves related to the training of several models and plot interesting datas about the training dynamic #####\n",
    "\n",
    "### LOAD ###\n",
    "def load_data_dictionnary(model_file_name, date):\n",
    "    \"\"\" Data contains are : training_loss, validation_loss, accuracy, kappa_training_loss, kappa_validation_loss, kappa_accuracy\"\"\"\n",
    "    training_loss = np.loadtxt('Classifiers/' + date + '/' + date + '_' +  model_file_name + '/figures/training_loss_of_' + date + '_' + model_file_name +'.txt', delimiter=\",\", skiprows=1)\n",
    "    validation_loss = np.loadtxt('Classifiers/' + date + '/' + date + '_' +  model_file_name + '/figures/validation_loss_of_' + date + '_' + model_file_name +'.txt', delimiter=\",\", skiprows=1)\n",
    "    accuracy = np.loadtxt('Classifiers/' + date + '/' + date + '_' +  model_file_name + '/figures/accuracy_of_' + date + '_' + model_file_name +'.txt', delimiter=\",\", skiprows=1)\n",
    "    kappa_training_loss = np.loadtxt('Classifiers/' + date + '/' + date + '_' +  model_file_name + '/figures/kappa_training_loss_of_' + date + '_' + model_file_name +'.txt', delimiter=\",\", skiprows=1)\n",
    "    kappa_validation_loss = np.loadtxt('Classifiers/' + date + '/' + date + '_' +  model_file_name + '/figures/kappa_validation_loss_of_' + date + '_' + model_file_name +'.txt', delimiter=\",\", skiprows=1)\n",
    "    kappa_accuracy = np.loadtxt('Classifiers/' + date + '/' + date + '_' +  model_file_name + '/figures/kappa_accuracy_of_' + date + '_' + model_file_name +'.txt', delimiter=\",\", skiprows=1)\n",
    "    \n",
    "    model_data_dictionnary = {'training loss' : training_loss, 'validation loss' : validation_loss, 'accuracy' : accuracy, \n",
    "                        'kappa training loss' : kappa_training_loss, 'kappa validation loss' : kappa_validation_loss,\n",
    "                        'kappa accuracy' : kappa_accuracy}    \n",
    "    \n",
    "    if os.path.exists('Classifiers/' + date + '/' + date + '_' +  model_file_name + '/' + 'fraction_minibatch' + model_file_name + '.txt') :\n",
    "        fraction_minibatch = torch.load('Classifiers/' + date + '/' + date + '_' +  model_file_name + '/' + date + '_' + 'fraction_minibatch' + model_file_name + '.txt',  delimiter=\",\", skiprows=1)\n",
    "        model_data_dictionnary['fraction minibatch'] = fraction_minibatch\n",
    "\n",
    "    if os.path.exists('Classifiers/' + date + '/' + date + '_' +  model_file_name + '/figures/accuracy_of_' + date + '_' + model_file_name + '_last_layer_fine_tuned' +'.txt') :\n",
    "        training_loss_fine_tuned = np.loadtxt('Classifiers/' + date + '/' + date + '_' +  model_file_name + '/figures/training_loss_of_' + date + '_' + model_file_name + '_last_layer_fine_tuned' + '.txt', delimiter=\",\", skiprows=1)\n",
    "        validation_loss_fine_tuned = np.loadtxt('Classifiers/' + date + '/' + date + '_' +  model_file_name + '/figures/validation_loss_of_' + date + '_' + model_file_name + '_last_layer_fine_tuned' + '.txt', delimiter=\",\", skiprows=1)\n",
    "        accuracy_fine_tuned = np.loadtxt('Classifiers/' + date + '/' + date + '_' +  model_file_name + '/figures/accuracy_of_' + date + '_' + model_file_name + '_last_layer_fine_tuned' + '.txt', delimiter=\",\", skiprows=1)\n",
    "        model_data_dictionnary = model_data_dictionnary | {'fine tuned training loss' : training_loss_fine_tuned, 'fine tuned validation loss' : validation_loss_fine_tuned, 'fine tuned accuracy' : accuracy_fine_tuned}\n",
    "    \n",
    "    if os.path.exists('Classifiers/' + date + '/' + date + '_' +  model_file_name + '/' + date + '_' +  model_file_name + '_first_layer_weight_bias.pt') :\n",
    "        weight_bias = torch.load('Classifiers/' + date + '/' + date + '_' +  model_file_name + '/' + date + '_' +  model_file_name + '_first_layer_weight_bias.pt')\n",
    "        model_data_dictionnary = model_data_dictionnary | weight_bias\n",
    "    \n",
    "    if os.path.exists('Classifiers/' + date + '/' + date + '_' +  model_file_name + '/' + date + '_' +  model_file_name + '_first_layer_weight_bias_trajectory.pt') :\n",
    "        weight_bias = torch.load('Classifiers/' + date + '/' + date + '_' +  model_file_name + '/' + date + '_' +  model_file_name + '_first_layer_weight_bias_trajectory.pt')\n",
    "        model_data_dictionnary = model_data_dictionnary | {'layers trajectories' : {1 : weight_bias}}\n",
    "    \n",
    "    if os.path.exists('Classifiers/' + date + '/' + date + '_' +  model_file_name + '/' + date + '_' +  model_file_name + '_second_layer_weight_bias_trajectory.pt') :\n",
    "        weight_bias = torch.load('Classifiers/' + date + '/' + date + '_' +  model_file_name + '/' + date + '_' +  model_file_name + '_second_layer_weight_bias_trajectory.pt')\n",
    "        model_data_dictionnary['layers trajectories'] = model_data_dictionnary['layers trajectories'] | {2 : weight_bias}\n",
    "        \n",
    "    return model_data_dictionnary\n",
    "\n",
    "def load_data_dictionnary_pre_29_05(model_file_name, date):\n",
    "    \"\"\" Data contains are : training_loss, validation_loss, accuracy, kappa_training_loss, kappa_validation_loss, kappa_accuracy\"\"\"\n",
    "    training_loss = np.loadtxt('Classifiers/' + date + '/' + date + '_' +  model_file_name + '/figures/loss_training_of_' + date + '_' + model_file_name +'.txt', delimiter=\",\", skiprows=1)\n",
    "    validation_loss = np.loadtxt('Classifiers/' + date + '/' + date + '_' +  model_file_name + '/figures/validation_loss_of_' + date + '_' + model_file_name +'.txt', delimiter=\",\", skiprows=1)\n",
    "    accuracy = np.loadtxt('Classifiers/' + date + '/' + date + '_' +  model_file_name + '/figures/accuracy_of_' + date + '_' + model_file_name +'.txt', delimiter=\",\", skiprows=1)\n",
    "    kappa_training_loss = np.loadtxt('Classifiers/' + date + '/' + date + '_' +  model_file_name + '/figures/kappa_loss_training_' + date + '_' + model_file_name +'.txt', delimiter=\",\", skiprows=1)\n",
    "    kappa_validation_loss = np.loadtxt('Classifiers/' + date + '/' + date + '_' +  model_file_name + '/figures/kappa_loss_validation_' + date + '_' + model_file_name +'.txt', delimiter=\",\", skiprows=1)\n",
    "    kappa_accuracy = np.loadtxt('Classifiers/' + date + '/' + date + '_' +  model_file_name + '/figures/kappa_accuracy_' + date + '_' + model_file_name +'.txt', delimiter=\",\", skiprows=1)\n",
    "    \n",
    "    model_data_dictionnary = {'training loss' : training_loss, 'validation loss' : validation_loss, 'accuracy' : accuracy, \n",
    "                        'kappa training loss' : kappa_training_loss, 'kappa validation loss' : kappa_validation_loss,\n",
    "                        'kappa accuracy' : kappa_accuracy}\n",
    "    return model_data_dictionnary\n",
    "\n",
    "### CONVERGENCE SPEED ###\n",
    "\n",
    "def convergence_speed(curve, ref_curve, delta = 1e-3,observation_rate=10):\n",
    "    if np.size(np.where((curve - (np.max(ref_curve)-delta) > 0))[0]) > 0 :\n",
    "        return np.where((curve - (np.max(ref_curve)-delta) > 0))[0][0]*observation_rate\n",
    "    else : \n",
    "        return -1e8\n",
    "\n",
    "def convergence_speed_plot(curve_dictionnary, color_list, marker_list, x_list, delta=1e-3, save=True, save_path = '', save_name_peculiarity=''):\n",
    "    convergence_speed_dictionnary = deepcopy(curve_dictionnary)\n",
    "    for n_hidden_units in curve_dictionnary:\n",
    "        for type_of_training in curve_dictionnary[n_hidden_units] :\n",
    "            for architecture in curve_dictionnary[n_hidden_units][type_of_training]:\n",
    "                if type_of_training != 'First trained + Last fine tuned' :\n",
    "                    convergence_speed_dictionnary[n_hidden_units][type_of_training][architecture] = convergence_speed(curve_dictionnary[n_hidden_units][type_of_training][architecture]['accuracy'][:,1], curve_dictionnary[n_hidden_units]['Reference']['2 layers']['accuracy'][:,1], delta)\n",
    "                    plt.plot(x_list[architecture], convergence_speed_dictionnary[n_hidden_units][type_of_training][architecture], marker = marker_list[type_of_training], markersize = '13', markeredgecolor = color_list[n_hidden_units], markerfacecolor = 'None')       \n",
    "                else : \n",
    "                    convergence_speed_dictionnary[n_hidden_units][type_of_training][architecture] = convergence_speed(curve_dictionnary[n_hidden_units][type_of_training][architecture]['fine tuned accuracy'][:,1], curve_dictionnary[n_hidden_units]['Reference']['2 layers']['accuracy'][:,1], delta)\n",
    "                    plt.plot(x_list[architecture], convergence_speed_dictionnary[n_hidden_units][type_of_training][architecture], marker = marker_list[type_of_training], markersize = '13', color = color_list[n_hidden_units])       \n",
    "                 \n",
    "    legend_hu = []\n",
    "    legend_training_type = []\n",
    "    for i, n_hidden_units in enumerate(convergence_speed_dictionnary):\n",
    "        legend_hu += [Line2D([0], [0], color = color_list[n_hidden_units], marker='.', linestyle='None', label = n_hidden_units)]\n",
    "        if i == 0:\n",
    "            for type_of_training in convergence_speed_dictionnary[n_hidden_units]:\n",
    "                if type_of_training != 'First trained + Last fine tuned' :\n",
    "                    legend_training_type += [Line2D([0], [0], markeredgecolor= 'black', markerfacecolor='None', marker = marker_list[type_of_training], linestyle = 'None', label = type_of_training)]\n",
    "                else : \n",
    "                    legend_training_type += [Line2D([0], [0], color= 'black', marker = marker_list[type_of_training], linestyle = 'None', label = type_of_training)]\n",
    "    legend_elements = legend_hu + legend_training_type\n",
    "    legend = plt.legend(handles=legend_elements, loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    for handle in legend.legend_handles:\n",
    "        handle.set_markersize(15)\n",
    "    plt.xlabel('Number of layers')\n",
    "    plt.ylabel('Number of iterations')\n",
    "    plt.title('Convergence speed of training \\nfor the different architectures and types of training', pad = 20)\n",
    "    y_max = np.max([convergence_speed_dictionnary[n_hidden_units][type_of_training][architecture] \n",
    "                for n_hidden_units in convergence_speed_dictionnary\n",
    "                for type_of_training in convergence_speed_dictionnary[n_hidden_units]\n",
    "                for architecture in convergence_speed_dictionnary[n_hidden_units][type_of_training]])\n",
    "    plt.ylim(-0.05*y_max, 1.05*y_max)\n",
    "    plt.xticks([x for key, x in x_list.items()])\n",
    "    plt.grid()\n",
    "    if save :\n",
    "        plt.savefig(save_path + 'convergence_speed_' + save_name_peculiarity + '.png', bbox_inches='tight')\n",
    "        plt.savefig(save_path + 'convergence_speed_' + save_name_peculiarity + '.svg', bbox_inches='tight')\n",
    "    plt.show()  \n",
    "    return\n",
    "\n",
    "def normalized_convergence_speed_plot(curve_dictionnary, color_list, marker_list, x_list, delta=1e-3, save=True, save_path = '', save_name_peculiarity=''):\n",
    "    convergence_speed_dictionnary = deepcopy(curve_dictionnary)\n",
    "    for n_hidden_units in curve_dictionnary:\n",
    "        for type_of_training in curve_dictionnary[n_hidden_units] :\n",
    "            for architecture in curve_dictionnary[n_hidden_units][type_of_training]:\n",
    "                if type_of_training != 'First trained + Last fine tuned' :\n",
    "                    convergence_speed_dictionnary[n_hidden_units][type_of_training][architecture] = convergence_speed(curve_dictionnary[n_hidden_units][type_of_training][architecture]['accuracy'][:,1], curve_dictionnary[n_hidden_units]['Reference']['2 layers']['accuracy'][:,1], delta)/convergence_speed(curve_dictionnary[n_hidden_units]['Reference']['2 layers']['accuracy'][:,1], curve_dictionnary[n_hidden_units]['Reference']['2 layers']['accuracy'][:,1], delta)\n",
    "                    if type_of_training == 'Reference':\n",
    "                        plt.plot(x_list[architecture], convergence_speed_dictionnary[n_hidden_units][type_of_training][architecture], marker = marker_list[type_of_training], markersize = '12', color = 'black')\n",
    "                    else :\n",
    "                        plt.plot(x_list[architecture], convergence_speed_dictionnary[n_hidden_units][type_of_training][architecture], marker = marker_list[type_of_training], markersize = '12', markerfacecolor = 'none', markeredgecolor = color_list[n_hidden_units])\n",
    "                else :\n",
    "                    convergence_speed_dictionnary[n_hidden_units][type_of_training][architecture] = convergence_speed(curve_dictionnary[n_hidden_units][type_of_training][architecture]['fine tuned accuracy'][:,1], curve_dictionnary[n_hidden_units]['Reference']['2 layers']['accuracy'][:,1], delta)/convergence_speed(curve_dictionnary[n_hidden_units]['Reference']['2 layers']['accuracy'][:,1], curve_dictionnary[n_hidden_units]['Reference']['2 layers']['accuracy'][:,1], delta)\n",
    "                    plt.plot(x_list[architecture], convergence_speed_dictionnary[n_hidden_units][type_of_training][architecture], marker = marker_list[type_of_training], markersize = '12', markerfacecolor = color_list[n_hidden_units], markeredgecolor = color_list[n_hidden_units])\n",
    "\n",
    "    legend_hu = []\n",
    "    legend_training_type = []\n",
    "    for i, n_hidden_units in enumerate(convergence_speed_dictionnary):\n",
    "        legend_hu += [Line2D([0], [0], color = color_list[n_hidden_units], marker='.', linestyle='None', label = n_hidden_units)]\n",
    "        if i == 0:\n",
    "            for type_of_training in convergence_speed_dictionnary[n_hidden_units]:\n",
    "                if type_of_training != 'First trained + Last fine tuned' :\n",
    "                    legend_training_type += [Line2D([0], [0], marker = marker_list[type_of_training], linestyle='None', markeredgecolor='black', markerfacecolor='None', label = type_of_training)]\n",
    "                else : \n",
    "                    legend_training_type += [Line2D([0], [0], marker = marker_list[type_of_training], linestyle='None', markeredgecolor='black', markerfacecolor='black', label = type_of_training)]\n",
    "    legend_elements = legend_hu + legend_training_type\n",
    "    legend = plt.legend(handles=legend_elements, loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    for handle in legend.legend_handles:\n",
    "        handle.set_markersize(15)\n",
    "    plt.xlabel('Number of layers')\n",
    "    plt.ylabel('Number of iterations')\n",
    "    plt.title('Normalized convergence speed of training \\nfor different architectures and types of training', pad = 20)\n",
    "    y_max = np.max([convergence_speed_dictionnary[n_hidden_units][type_of_training][architecture] \n",
    "                for n_hidden_units in convergence_speed_dictionnary\n",
    "                for type_of_training in convergence_speed_dictionnary[n_hidden_units]\n",
    "                for architecture in convergence_speed_dictionnary[n_hidden_units][type_of_training]])\n",
    "    plt.ylim(-0.1, y_max + 0.1)\n",
    "    plt.xticks([x for key, x in x_list.items()])\n",
    "    plt.grid()\n",
    "    if save :\n",
    "        plt.savefig(save_path + 'normalized_convergence_speed_' + save_name_peculiarity + '.png', bbox_inches='tight')\n",
    "        plt.savefig(save_path + 'normalized_convergence_speed_' + save_name_peculiarity + '.svg', bbox_inches='tight')\n",
    "    plt.show()  \n",
    "    return\n",
    "\n",
    "### MAXIMUM ACCURACY ###\n",
    "\n",
    "def max_accuracy_plot(curve_dictionnary, color_list, marker_list, x_list, save=True, save_path = '', save_name_peculiarity='') :\n",
    "    max_accuracy_dictionnary = deepcopy(curve_dictionnary)\n",
    "    for n_hidden_units in curve_dictionnary:\n",
    "        for type_of_training in curve_dictionnary[n_hidden_units] :\n",
    "            for architecture in curve_dictionnary[n_hidden_units][type_of_training]:\n",
    "                if type_of_training != 'First trained + Last fine tuned' :\n",
    "                    max_accuracy_dictionnary[n_hidden_units][type_of_training][architecture] = np.max(curve_dictionnary[n_hidden_units][type_of_training][architecture]['accuracy'][:,1])\n",
    "                    plt.plot(x_list[architecture], max_accuracy_dictionnary[n_hidden_units][type_of_training][architecture], marker = marker_list[type_of_training], markersize = '12', markerfacecolor = 'None', markeredgecolor = color_list[n_hidden_units])\n",
    "                else : \n",
    "                    max_accuracy_dictionnary[n_hidden_units][type_of_training][architecture] = np.max(curve_dictionnary[n_hidden_units][type_of_training][architecture]['fine tuned accuracy'][:,1])\n",
    "                    plt.plot(x_list[architecture], max_accuracy_dictionnary[n_hidden_units][type_of_training][architecture], marker = marker_list[type_of_training], markersize = '12', markerfacecolor = color_list[n_hidden_units], markeredgecolor = color_list[n_hidden_units])\n",
    "\n",
    "    legend_hu = []\n",
    "    legend_training_type = []\n",
    "    for i, n_hidden_units in enumerate(max_accuracy_dictionnary):\n",
    "        legend_hu += [Line2D([0], [0], color = color_list[n_hidden_units], marker = '.', linestyle='None', label = n_hidden_units)]\n",
    "        if i == 0:\n",
    "            for type_of_training in max_accuracy_dictionnary[n_hidden_units]:\n",
    "                if type_of_training != 'First trained + Last fine tuned' :\n",
    "                    legend_training_type += [Line2D([0], [0], markeredgecolor = 'black', markerfacecolor = 'None', marker = marker_list[type_of_training], linestyle='None', label = type_of_training)]\n",
    "                else : \n",
    "                    legend_training_type += [Line2D([0], [0], markeredgecolor = 'black', markerfacecolor = 'black', marker = marker_list[type_of_training], linestyle='None', label = type_of_training)]\n",
    "    legend_elements = legend_hu + legend_training_type\n",
    "    legend = plt.legend(handles=legend_elements, loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    for handle in legend.legend_handles:\n",
    "        handle.set_markersize(15)\n",
    "    plt.xlabel('Number of layers')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Maximum accuracy for\\n the different architectures and types of training', pad = 20)\n",
    "    y_max = np.max([max_accuracy_dictionnary[n_hidden_units][type_of_training][architecture] \n",
    "                for n_hidden_units in max_accuracy_dictionnary\n",
    "                for type_of_training in max_accuracy_dictionnary[n_hidden_units]\n",
    "                for architecture in max_accuracy_dictionnary[n_hidden_units][type_of_training]])\n",
    "    y_min = np.min([max_accuracy_dictionnary[n_hidden_units][type_of_training][architecture] \n",
    "                for n_hidden_units in max_accuracy_dictionnary\n",
    "                for type_of_training in max_accuracy_dictionnary[n_hidden_units]\n",
    "                for architecture in max_accuracy_dictionnary[n_hidden_units][type_of_training]])\n",
    "    plt.ylim(y_min - 0.01, y_max + 0.01)\n",
    "    plt.xticks([x for key, x in x_list.items()])\n",
    "    plt.grid()\n",
    "    if save :\n",
    "        plt.savefig(save_path + 'max_accuracy_' + save_name_peculiarity + '.png', bbox_inches='tight')\n",
    "        plt.savefig(save_path + 'max_accuracy_' + save_name_peculiarity + '.svg', bbox_inches='tight')\n",
    "    plt.show()  \n",
    "    return\n",
    "\n",
    "### ACCURACY TRAJECTORY ###\n",
    "\n",
    "def accuracy_trajectory_plot(curve_dictionnary, color_list, marker_list, x_lim = None, y_lim = None, save=True, save_path = '', save_name_peculiarity='', observation_rate = 10) :\n",
    "    for n_hidden_units in curve_dictionnary:\n",
    "        for type_of_training in curve_dictionnary[n_hidden_units] :\n",
    "            for architecture in curve_dictionnary[n_hidden_units][type_of_training]:\n",
    "                if type_of_training != 'First trained + Last fine tuned' :\n",
    "                    accuracy = curve_dictionnary[n_hidden_units][type_of_training][architecture]['accuracy']\n",
    "                    x_max = x_lim[1] if x_lim is not None else curve_dictionnary[n_hidden_units][type_of_training][architecture]['accuracy'][:,0][-1]*observation_rate\n",
    "                    accuracy[:,1] = low_pass_filter(accuracy[:,1], 0.10)\n",
    "                    len_accuracy = len(accuracy[accuracy[:,0] < x_max])\n",
    "                    plt.plot(accuracy[:,0], accuracy[:,1], marker = marker_list[type_of_training], markersize = '11', markerfacecolor = 'None', markeredgecolor = color_list[n_hidden_units][architecture], markevery = int(len_accuracy/10), color = color_list[n_hidden_units][architecture])\n",
    "                            \n",
    "                else :\n",
    "                    accuracy = curve_dictionnary[n_hidden_units][type_of_training][architecture]['fine tuned accuracy']\n",
    "                    plt.plot(accuracy[:,0], accuracy[:,1], marker = marker_list[type_of_training], markersize = '11', markerfacecolor = color_list[n_hidden_units][architecture], markeredgecolor = color_list[n_hidden_units][architecture], color = color_list[n_hidden_units][architecture])\n",
    "    labels=[]\n",
    "    legend_hu = []\n",
    "    legend_training_type = []\n",
    "    for i, n_hidden_units in enumerate(curve_dictionnary):\n",
    "        for j, type_of_training in enumerate(curve_dictionnary[n_hidden_units]):\n",
    "            for k, architecture in enumerate(curve_dictionnary[n_hidden_units][type_of_training]):\n",
    "                if i == 0 and k == 0:\n",
    "                    if type_of_training != 'First trained + Last fine tuned' :\n",
    "                        legend_training_type += [Line2D([0], [0], markeredgecolor = 'black', markerfacecolor = 'None', marker = marker_list[type_of_training], linestyle='None', label = type_of_training)]\n",
    "                    else : \n",
    "                        legend_training_type += [Line2D([0], [0], markeredgecolor = 'black', markerfacecolor = 'black', marker = marker_list[type_of_training], linestyle='None', label = type_of_training)]\n",
    "                if np.sum([n_hidden_units + ' - ' + architecture==label for label in labels])==0:    \n",
    "                    legend_hu += [Line2D([0], [0], color = color_list[n_hidden_units][architecture], linewidth=5, label = n_hidden_units + ' - ' + architecture)]\n",
    "                    labels += [n_hidden_units + ' - ' + architecture]\n",
    "    legend_elements = legend_hu + legend_training_type\n",
    "    legend = plt.legend(handles=legend_elements, loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    for handle in legend.legend_handles:\n",
    "        handle.set_markersize(15)\n",
    "    plt.xlabel('Number of iterations')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Accuracy during training for\\n the different architectures and types of training', pad = 20)\n",
    "    x_max = np.max([np.max(curve_dictionnary[n_hidden_units][type_of_training][architecture]['accuracy'][:,0])\n",
    "                    for n_hidden_units in curve_dictionnary\n",
    "                    for type_of_training in curve_dictionnary[n_hidden_units]\n",
    "                    for architecture in curve_dictionnary[n_hidden_units][type_of_training]]) if x_lim == None else x_lim[1]\n",
    "    plt.xlim(-100, x_max)\n",
    "    y_max = np.max([np.max(curve_dictionnary[n_hidden_units][type_of_training][architecture]['accuracy'][:,1])\n",
    "                for n_hidden_units in curve_dictionnary\n",
    "                for type_of_training in curve_dictionnary[n_hidden_units]\n",
    "                for architecture in curve_dictionnary[n_hidden_units][type_of_training]]) if y_lim == None else y_lim[1] \n",
    "    y_min = np.min([np.min(curve_dictionnary[n_hidden_units][type_of_training][architecture]['accuracy'][:,1])\n",
    "                for n_hidden_units in curve_dictionnary\n",
    "                for type_of_training in curve_dictionnary[n_hidden_units]\n",
    "                for architecture in curve_dictionnary[n_hidden_units][type_of_training]]) if y_lim == None else y_lim[0] \n",
    "    \n",
    "    plt.ylim(y_min - 0.01, y_max + 0.01)\n",
    "    plt.grid()\n",
    "    if save :\n",
    "        plt.savefig(save_path + 'accuracy_trajectories' + save_name_peculiarity + '.png', bbox_inches='tight')\n",
    "        plt.savefig(save_path + 'accuracy_trajectories' + save_name_peculiarity + '.svg', bbox_inches='tight')\n",
    "    plt.show()  \n",
    "    return\n",
    "\n",
    "### LOSS TRAJECTORY ###\n",
    "\n",
    "def loss_trajectory_plot(curve_dictionnary, color_list, marker_list, x_lim = None, y_lim = None, save=True, save_path = '', save_name_peculiarity='', observation_rate = 10) :\n",
    "    for n_hidden_units in curve_dictionnary:\n",
    "        for type_of_training in curve_dictionnary[n_hidden_units] :\n",
    "            for architecture in curve_dictionnary[n_hidden_units][type_of_training]:\n",
    "                if type_of_training != 'First trained + Last fine tuned':\n",
    "                    training_loss = curve_dictionnary[n_hidden_units][type_of_training][architecture]['training loss']\n",
    "                    validation_loss = curve_dictionnary[n_hidden_units][type_of_training][architecture]['validation loss']\n",
    "                    training_loss[:,1] = low_pass_filter(training_loss[:,1], 0.30)\n",
    "                    validation_loss[:,1] = low_pass_filter(validation_loss[:,1], 0.30)\n",
    "                    x_max = x_lim[1] if x_lim is not None else training_loss[:,0][-1]*observation_rate\n",
    "                    len_training_loss = len(training_loss[training_loss[:,0] < x_max])\n",
    "                    plt.plot(training_loss[:,0], training_loss[:,1], marker = marker_list[type_of_training], markersize = '11', markerfacecolor = 'None', markeredgecolor = color_list[n_hidden_units][architecture], markevery = int(len_training_loss/10), color = color_list[n_hidden_units][architecture])\n",
    "                    x_max = x_lim[1] if x_lim is not None else validation_loss[:,0][-1]*observation_rate\n",
    "                    len_validation_loss = len(validation_loss[validation_loss[:,0] < x_max])\n",
    "                    plt.plot(validation_loss[:,0], validation_loss[:,1], marker = marker_list[type_of_training], markersize = '11', markerfacecolor = 'None', markeredgecolor = color_list[n_hidden_units][architecture], markevery = int(len_validation_loss/10), linestyle = ':', color = color_list[n_hidden_units][architecture])\n",
    "        \n",
    "                else : \n",
    "                    training_loss = curve_dictionnary[n_hidden_units][type_of_training][architecture]['fine tuned training loss']\n",
    "                    plt.plot(training_loss[:,0], training_loss[:,1], marker = marker_list[type_of_training], markersize = '11', markerfacecolor = color_list[n_hidden_units][architecture], markeredgecolor = color_list[n_hidden_units][architecture], color = color_list[n_hidden_units][architecture])\n",
    "                    validation_loss = curve_dictionnary[n_hidden_units][type_of_training][architecture]['fine tuned validation loss']\n",
    "                    plt.plot(validation_loss[:,0], validation_loss[:,1], marker = marker_list[type_of_training], markersize = '11', markerfacecolor = color_list[n_hidden_units][architecture], markeredgecolor = color_list[n_hidden_units][architecture], linestyle = ':', color = color_list[n_hidden_units][architecture])\n",
    "    labels=[]\n",
    "    legend_hu = []\n",
    "    legend_training_type = []\n",
    "    legend_loss_type = [Line2D([0], [0], color = 'black', label = 'Training loss'), \n",
    "                        Line2D([0], [0], color = 'black', linestyle = ':', label = 'Validation_loss')]\n",
    "    for i, n_hidden_units in enumerate(curve_dictionnary):\n",
    "        for j, type_of_training in enumerate(curve_dictionnary[n_hidden_units]): \n",
    "            for k, architecture in enumerate(curve_dictionnary[n_hidden_units][type_of_training]):\n",
    "                if i == 0 and k == 0:\n",
    "                    if type_of_training != 'First trained + Last fine tuned' :\n",
    "                        legend_training_type += [Line2D([0], [0], markeredgecolor = 'black', markerfacecolor = 'None', marker = marker_list[type_of_training], linestyle='None', label = type_of_training)]\n",
    "                    else : \n",
    "                        legend_training_type += [Line2D([0], [0], markeredgecolor = 'black', markerfacecolor = 'black', marker = marker_list[type_of_training], linestyle='None', label = type_of_training)]\n",
    "                if np.sum([n_hidden_units + ' - ' + architecture==label for label in labels])==0:    \n",
    "                    legend_hu += [Line2D([0], [0], color = color_list[n_hidden_units][architecture], linewidth=5, label = n_hidden_units + ' - ' + architecture)]\n",
    "                    labels += [n_hidden_units + ' - ' + architecture]\n",
    "    legend_elements = legend_loss_type + legend_hu + legend_training_type\n",
    "    legend = plt.legend(handles=legend_elements, loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    for handle in legend.legend_handles:\n",
    "        handle.set_markersize(15)\n",
    "    plt.xlabel('Number of iterations')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Loss during training for \\nthe different architectures and types of training', pad = 20)\n",
    "    x_max = np.max([np.max(curve_dictionnary[n_hidden_units][type_of_training][architecture]['training loss'][:,0])\n",
    "                    for n_hidden_units in curve_dictionnary\n",
    "                    for type_of_training in curve_dictionnary[n_hidden_units]\n",
    "                    for architecture in curve_dictionnary[n_hidden_units][type_of_training]]) if x_lim == None else x_lim[1]\n",
    "    plt.xlim(0, x_max)\n",
    "    y_max = np.max([np.max(curve_dictionnary[n_hidden_units][type_of_training][architecture]['training loss'][:,1]) \n",
    "                for n_hidden_units in curve_dictionnary\n",
    "                for type_of_training in curve_dictionnary[n_hidden_units]\n",
    "                for architecture in curve_dictionnary[n_hidden_units][type_of_training]]\n",
    "                + [np.max(curve_dictionnary[n_hidden_units][type_of_training][architecture]['validation loss'][:,1])\n",
    "                for n_hidden_units in curve_dictionnary\n",
    "                for type_of_training in curve_dictionnary[n_hidden_units]\n",
    "                for architecture in curve_dictionnary[n_hidden_units][type_of_training]]) if y_lim == None else y_lim[1]    \n",
    "    plt.ylim(-0.01, y_max + 0.01)\n",
    "    plt.grid()\n",
    "    if save :\n",
    "        plt.savefig(save_path + 'loss_trajectories' + save_name_peculiarity + '.png', bbox_inches='tight')\n",
    "        plt.savefig(save_path + 'loss_trajectories' + save_name_peculiarity + '.svg', bbox_inches='tight')\n",
    "    plt.show()  \n",
    "    return\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### STATISTICS - Load a dictionnary of curves related to the training of several samples of several models and plot interesting datas about the training dynamic #####\n",
    "\n",
    "\n",
    "### LOAD ###\n",
    "\n",
    "def load_multi_saves_data_dictionnary(model_file_name, date):\n",
    "    \"\"\"\n",
    "    Charge les résultats moyens (loss, accuracy, etc.)\n",
    "    \"\"\"\n",
    "    model_path = Path('Classifiers') / date / f\"{date}_{model_file_name}\"\n",
    "    model_data_dictionnary = {}\n",
    "    save_index = 1\n",
    "\n",
    "    if not model_path.exists():\n",
    "        print(f\"[WARNING] Dossier inexistant : {model_path}\")\n",
    "        return model_data_dictionnary\n",
    "\n",
    "    for save in model_path.iterdir():\n",
    "        if not save.is_dir():\n",
    "            continue\n",
    "\n",
    "        save_data = {}\n",
    "        figures_path = save / 'figures'\n",
    "\n",
    "        # Essayer de charger les fichiers principaux (avec test)\n",
    "        for metric in ['training_loss', 'validation_loss', 'accuracy',\n",
    "                       'kappa_training_loss', 'kappa_validation_loss', 'kappa_accuracy']:\n",
    "            file_path = figures_path / f\"{metric}_of_{date}_{model_file_name}.txt\"\n",
    "            if file_path.exists():\n",
    "                save_data[metric.replace('_', ' ')] = np.loadtxt(file_path, delimiter=\",\", skiprows=1)\n",
    "\n",
    "        # Essayer de charger les fichiers \"last_layer_fine_tuned\"\n",
    "        for metric in ['training_loss', 'validation_loss', 'accuracy']:\n",
    "            file_path = figures_path / f\"{metric}_of_{date}_{model_file_name}_last_layer_fine_tuned.txt\"\n",
    "            if file_path.exists():\n",
    "                save_data[f\"fine tuned {metric.replace('_', ' ')}\"] = np.loadtxt(file_path, delimiter=\",\", skiprows=1)\n",
    "\n",
    "        # Essayer de charger les poids/biais\n",
    "        first_layer_path = save / f\"{date}_{model_file_name}_first_layer_weight_bias.pt\"\n",
    "        if first_layer_path.exists():\n",
    "            try:\n",
    "                weight_bias = torch.load(first_layer_path)\n",
    "                save_data = save_data | weight_bias\n",
    "            except Exception as e:\n",
    "                print(f\"[ERROR] Impossible de charger {first_layer_path} : {e}\")\n",
    "\n",
    "        # Essayer de charger les trajectoires\n",
    "        layers_trajectories = {}\n",
    "\n",
    "        first_traj_path = save / f\"{date}_{model_file_name}_first_layer_weight_bias_trajectory.pt\"\n",
    "        if first_traj_path.exists():\n",
    "            try:\n",
    "                layers_trajectories[1] = torch.load(first_traj_path)\n",
    "            except Exception as e:\n",
    "                print(f\"[ERROR] Impossible de charger {first_traj_path} : {e}\")\n",
    "\n",
    "        second_traj_path = save / f\"{date}_{model_file_name}_second_layer_weight_bias_trajectory.pt\"\n",
    "        if second_traj_path.exists():\n",
    "            try:\n",
    "                layers_trajectories[2] = torch.load(second_traj_path)\n",
    "            except Exception as e:\n",
    "                print(f\"[ERROR] Impossible de charger {second_traj_path} : {e}\")\n",
    "\n",
    "        if layers_trajectories:\n",
    "            save_data['layers trajectories'] = layers_trajectories\n",
    "\n",
    "        # Stocker dans le dictionnaire final si on a trouvé des données\n",
    "        if save_data:\n",
    "            model_data_dictionnary[f'save {save_index}'] = save_data\n",
    "            save_index += 1\n",
    "\n",
    "    return model_data_dictionnary\n",
    "\n",
    "\n",
    "## If several kappa = log(n)/log(d) ##\n",
    "\n",
    "def load_multi_kappa_multi_saves_data_dictionnary(model_file_name, date):\n",
    "    \"\"\"\n",
    "    Charge les résultats moyens (loss, accuracy, etc.) sous la forme d'un dictionnaire [kappa][save_index][metric]\n",
    "    \"\"\"\n",
    "    model_path = Path('Classifiers') / date / f\"{date}_{model_file_name}\"\n",
    "    model_data_dictionnary = {}\n",
    "    save_index = 1\n",
    "\n",
    "    if not model_path.exists():\n",
    "        print(f\"[WARNING] Dossier inexistant : {model_path}\")\n",
    "        return model_data_dictionnary\n",
    "\n",
    "    for kappa in model_path.iterdir():\n",
    "        model_data_dictionnary[kappa] = {}\n",
    "\n",
    "        for save in (model_path / kappa).iterdir():\n",
    "            if not save.is_dir():\n",
    "                continue\n",
    "\n",
    "            save_data = {}\n",
    "            figures_path = save / 'figures'\n",
    "\n",
    "            # Essayer de charger les fichiers principaux (avec test)\n",
    "            for metric in ['training_loss', 'validation_loss', 'accuracy',\n",
    "                        'kappa_training_loss', 'kappa_validation_loss', 'kappa_accuracy']:\n",
    "                file_path = figures_path / f\"{metric}_of_{date}_{model_file_name}.txt\"\n",
    "                if file_path.exists():\n",
    "                    save_data[metric.replace('_', ' ')] = np.loadtxt(file_path, delimiter=\",\", skiprows=1)\n",
    "\n",
    "            # Essayer de charger les fichiers \"last_layer_fine_tuned\"\n",
    "            for metric in ['training_loss', 'validation_loss', 'accuracy']:\n",
    "                file_path = figures_path / f\"{metric}_of_{date}_{model_file_name}_last_layer_fine_tuned.txt\"\n",
    "                if file_path.exists():\n",
    "                    save_data[f\"fine tuned {metric.replace('_', ' ')}\"] = np.loadtxt(file_path, delimiter=\",\", skiprows=1)\n",
    "\n",
    "            # Essayer de charger les poids/biais\n",
    "            first_layer_path = save / f\"{date}_{model_file_name}_first_layer_weight_bias.pt\"\n",
    "            if first_layer_path.exists():\n",
    "                try:\n",
    "                    weight_bias = torch.load(first_layer_path)\n",
    "                    save_data = save_data | weight_bias\n",
    "                except Exception as e:\n",
    "                    print(f\"[ERROR] Impossible de charger {first_layer_path} : {e}\")\n",
    "\n",
    "            # Essayer de charger les trajectoires\n",
    "            layers_trajectories = {}\n",
    "\n",
    "            first_traj_path = save / f\"{date}_{model_file_name}_first_layer_weight_bias_trajectory.pt\"\n",
    "            if first_traj_path.exists():\n",
    "                try:\n",
    "                    layers_trajectories[1] = torch.load(first_traj_path)\n",
    "                except Exception as e:\n",
    "                    print(f\"[ERROR] Impossible de charger {first_traj_path} : {e}\")\n",
    "\n",
    "            second_traj_path = save / f\"{date}_{model_file_name}_second_layer_weight_bias_trajectory.pt\"\n",
    "            if second_traj_path.exists():\n",
    "                try:\n",
    "                    layers_trajectories[2] = torch.load(second_traj_path)\n",
    "                except Exception as e:\n",
    "                    print(f\"[ERROR] Impossible de charger {second_traj_path} : {e}\")\n",
    "\n",
    "            if layers_trajectories:\n",
    "                save_data['layers trajectories'] = layers_trajectories\n",
    "\n",
    "            # Stocker dans le dictionnaire final si on a trouvé des données\n",
    "            if save_data:\n",
    "                model_data_dictionnary[kappa][f'save {save_index}'] = save_data\n",
    "                save_index += 1\n",
    "\n",
    "    return model_data_dictionnary\n",
    "\n",
    "### CONVERT SEVERAL SAMPLES into ONE MEAN CURVE (+ ERROR) ###\n",
    "\n",
    "def convert_to_statistical_data_dictionnary(model_data_dictionnary, outlier_filter=True):\n",
    "    \"\"\"\n",
    "    model_data_dictionnary structure :\n",
    "        { 'save 1': { 'metric_name': array, ... }, ... }\n",
    "    Returns :\n",
    "        { 'mean': {metric_name: array}, 'error': {metric_name: array} }\n",
    "    \"\"\"\n",
    "    # Initialiser dictionnaires résultat\n",
    "    statistical_curve = {'mean': {}, 'error': {}}\n",
    "\n",
    "    # Pour chaque metric, construire la pile de toutes les saves alignées\n",
    "    metrics = list(next(iter(model_data_dictionnary.values())).keys())\n",
    "    n_saves = len(model_data_dictionnary)\n",
    "\n",
    "    for metric in metrics:\n",
    "            # Trouver la longueur minimale sur toutes les saves et metrics\n",
    "        min_length = np.min([\n",
    "            model_data_dictionnary[save][metric].shape[0]\n",
    "            for save in model_data_dictionnary\n",
    "        ])\n",
    "        # Stack des valeurs coupées à min_length\n",
    "        values_list = []\n",
    "        for save in model_data_dictionnary:\n",
    "            values = model_data_dictionnary[save][metric][:min_length, 1]\n",
    "            values_list.append(values)\n",
    "        \n",
    "        # Transformer en array (n_saves x min_length)\n",
    "        values_array = np.vstack(values_list)\n",
    "\n",
    "        # Moyenne et erreur-type absolue\n",
    "        mean_values = np.mean(values_array, axis=0)\n",
    "        error_values = np.std(values_array, axis=0) / np.sqrt(n_saves)  # erreur-type (SEM)\n",
    "\n",
    "        # On suppose que l'axe X est le même (prend celui du premier save)\n",
    "        x_axis = model_data_dictionnary[next(iter(model_data_dictionnary))][metric][:min_length, 0]\n",
    "\n",
    "        # Stocker résultat\n",
    "        statistical_curve['mean'][metric] = np.column_stack((x_axis, mean_values))\n",
    "        statistical_curve['error'][metric] = error_values/2\n",
    "\n",
    "        if outlier_filter:\n",
    "            outliers_indices = np.where(statistical_curve['error'][metric] > 0.03)\n",
    "            for outlier_index in outliers_indices :\n",
    "                statistical_curve['error'][metric][outlier_index] = 0\n",
    "    return statistical_curve\n",
    "\n",
    "\n",
    "### STATISTICAL ACCURACY ###\n",
    "\n",
    "# The statistical curves are gathered in a statistical curves dictionnary\n",
    "\n",
    "def statistical_accuracy_trajectory_plot(statistical_curve_dictionnary, n_saves, color_list, marker_list, x_lim = None, y_lim = None, save=True, save_path = '', save_name_peculiarity='', observation_rate = 10) :\n",
    "    for n_hidden_units in statistical_curve_dictionnary:\n",
    "        for type_of_training in statistical_curve_dictionnary[n_hidden_units] :\n",
    "            for architecture in statistical_curve_dictionnary[n_hidden_units][type_of_training]:\n",
    "                if type_of_training != 'First trained + Last fine tuned' :\n",
    "                    accuracy = statistical_curve_dictionnary[n_hidden_units][type_of_training][architecture]['mean']['accuracy']\n",
    "                    for i in range(1,len(accuracy[:,1])):\n",
    "                        if accuracy[i,1]<accuracy[i-1,1]-0.005:\n",
    "                            accuracy[i,1] = accuracy[i-1,1]\n",
    "                    accuracy_error = statistical_curve_dictionnary[n_hidden_units][type_of_training][architecture]['error']['accuracy']\n",
    "                    x_max = x_lim[1] if x_lim is not None else accuracy[:,0][-1]*observation_rate\n",
    "                    accuracy[:,1] = low_pass_filter(accuracy[:,1], 0.1)\n",
    "                    len_accuracy = len(accuracy[accuracy[:,0] < x_max])\n",
    "                    # plt.errorbar(accuracy[:,0], accuracy[:,1], yerr=accuracy_error, fmt='o', capsize=2, marker = marker_list[type_of_training], markersize = '4', markerfacecolor = 'None', markeredgecolor = color_list[n_hidden_units][architecture], markevery = int(len_accuracy/10), color = color_list[n_hidden_units][architecture])\n",
    "                    plt.errorbar(accuracy[:,0], accuracy[:,1], capsize=2, marker = marker_list[type_of_training], markersize = '11', markerfacecolor = 'None', markeredgecolor = color_list[n_hidden_units][architecture], markevery = int(len_accuracy/10), color = color_list[n_hidden_units][architecture])\n",
    "                else :\n",
    "                    accuracy = statistical_curve_dictionnary[n_hidden_units][type_of_training][architecture]['mean']['fine tuned accuracy']\n",
    "                    for i in range(1,len(accuracy[:,1])):\n",
    "                        if accuracy[i,1]<accuracy[i-1,1]-0.005:\n",
    "                            accuracy[i,1] = accuracy[i-1,1]\n",
    "                    accuracy_error = statistical_curve_dictionnary[n_hidden_units][type_of_training][architecture]['error']['fine tuned accuracy']\n",
    "                    x_max = x_lim[1] if x_lim is not None else statistical_curve_dictionnary[n_hidden_units][type_of_training][architecture]['mean']['fine tuned accuracy'][:,0][-1]\n",
    "                    len_accuracy = len(accuracy[accuracy[:,0] < x_max])\n",
    "                    # plt.errorbar(accuracy[:,0], accuracy[:,1], yerr=accuracy_error, fmt='o', marker = marker_list[type_of_training], markersize = '4', markerfacecolor = color_list[n_hidden_units][architecture], markeredgecolor = color_list[n_hidden_units][architecture], color = color_list[n_hidden_units][architecture])\n",
    "                    plt.errorbar(accuracy[:,0], accuracy[:,1], marker = marker_list[type_of_training], markersize = '11', markerfacecolor = color_list[n_hidden_units][architecture], markevery = int(len_accuracy/10), markeredgecolor = color_list[n_hidden_units][architecture], color = color_list[n_hidden_units][architecture])\n",
    "    \n",
    "    labels=[]\n",
    "    legend_hu = []\n",
    "    legend_training_type = []\n",
    "    for i, n_hidden_units in enumerate(statistical_curve_dictionnary):\n",
    "        for j, type_of_training in enumerate(statistical_curve_dictionnary[n_hidden_units]):\n",
    "            for k, architecture in enumerate(statistical_curve_dictionnary[n_hidden_units][type_of_training]):\n",
    "                if i == 0 and k == 0:\n",
    "                    if type_of_training != 'First trained + Last fine tuned' :\n",
    "                        legend_training_type += [Line2D([0], [0], markeredgecolor = 'black', markerfacecolor = 'None', marker = marker_list[type_of_training], linestyle='None', label = type_of_training)]\n",
    "                    else : \n",
    "                        legend_training_type += [Line2D([0], [0], markeredgecolor = 'black', markerfacecolor = 'black', marker = marker_list[type_of_training], linestyle='None', label = type_of_training)]\n",
    "                if np.sum([n_hidden_units + ' - ' + architecture==label for label in labels])==0:    \n",
    "                    legend_hu += [Line2D([0], [0], color = color_list[n_hidden_units][architecture], linewidth=5, label = n_hidden_units + ' - ' + architecture)]\n",
    "                    labels += [n_hidden_units + ' - ' + architecture]\n",
    "    legend_elements = legend_hu + legend_training_type\n",
    "    legend = plt.legend(handles=legend_elements, loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    for handle in legend.legend_handles:\n",
    "        handle.set_markersize(15)\n",
    "    plt.xlabel('Number of iterations')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title(f'Mean accuracy during training for\\n the different architectures and types of training\\non N = {n_saves} samples', pad = 20)\n",
    "    x_max = np.max([np.max(statistical_curve_dictionnary[n_hidden_units][type_of_training][architecture]['mean']['accuracy'][:,0])\n",
    "                    for n_hidden_units in statistical_curve_dictionnary\n",
    "                    for type_of_training in statistical_curve_dictionnary[n_hidden_units]\n",
    "                    for architecture in statistical_curve_dictionnary[n_hidden_units][type_of_training]]) if x_lim == None else x_lim[1]\n",
    "    plt.xlim(-100, x_max)\n",
    "    y_max = np.max([np.max(statistical_curve_dictionnary[n_hidden_units][type_of_training][architecture]['mean']['accuracy'][:,1])\n",
    "                for n_hidden_units in statistical_curve_dictionnary\n",
    "                for type_of_training in statistical_curve_dictionnary[n_hidden_units]\n",
    "                for architecture in statistical_curve_dictionnary[n_hidden_units][type_of_training]]) if y_lim == None else y_lim[1] \n",
    "    y_min = np.min([np.min(statistical_curve_dictionnary[n_hidden_units][type_of_training][architecture]['mean']['accuracy'][:,1])\n",
    "                for n_hidden_units in statistical_curve_dictionnary\n",
    "                for type_of_training in statistical_curve_dictionnary[n_hidden_units]\n",
    "                for architecture in statistical_curve_dictionnary[n_hidden_units][type_of_training]]) if y_lim == None else y_lim[0] \n",
    "    \n",
    "    plt.ylim(y_min - 0.01, y_max + 0.01)\n",
    "    plt.grid()\n",
    "    if save :\n",
    "        plt.savefig(save_path + 'accuracy_trajectories_' + save_name_peculiarity + '.png', bbox_inches='tight')\n",
    "        plt.savefig(save_path + 'accuracy_trajectories_' + save_name_peculiarity + '.svg', bbox_inches='tight')\n",
    "    plt.show()  \n",
    "    return\n",
    "\n",
    "\n",
    "### STATISTICAL LOSS ###\n",
    "\n",
    "def statistical_loss_trajectory_plot(statistical_curve_dictionnary, n_saves, color_list, marker_list, x_lim = None, y_lim = None, save=True, save_path = '', save_name_peculiarity='', observation_rate = 10) :\n",
    "    for n_hidden_units in statistical_curve_dictionnary:\n",
    "        for type_of_training in statistical_curve_dictionnary[n_hidden_units] :\n",
    "            for architecture in statistical_curve_dictionnary[n_hidden_units][type_of_training]:\n",
    "                if type_of_training != 'First trained + Last fine tuned':\n",
    "                    training_loss = statistical_curve_dictionnary[n_hidden_units][type_of_training][architecture]['mean']['training loss']\n",
    "                    training_loss_error = statistical_curve_dictionnary[n_hidden_units][type_of_training][architecture]['error']['training loss']\n",
    "                    validation_loss = statistical_curve_dictionnary[n_hidden_units][type_of_training][architecture]['mean']['validation loss']\n",
    "                    validation_loss_error = statistical_curve_dictionnary[n_hidden_units][type_of_training][architecture]['error']['validation loss']\n",
    "                    # training_loss[:,1] = low_pass_filter(training_loss[:,1], 0.30)\n",
    "                    # validation_loss[:,1] = low_pass_filter(validation_loss[:,1], 0.30)\n",
    "                    x_max = x_lim[1] if x_lim is not None else training_loss[:,0][-1]*observation_rate\n",
    "                    len_training_loss = len(training_loss[training_loss[:,0] < x_max])\n",
    "                    # plt.errorbar(training_loss[:,0], training_loss[:,1], training_loss_error, marker = marker_list[type_of_training], markersize = '4', markerfacecolor = 'None', markeredgecolor = color_list[n_hidden_units][architecture], markevery = int(len_training_loss/10), color = color_list[n_hidden_units][architecture])\n",
    "                    plt.errorbar(training_loss[:,0], training_loss[:,1], marker = marker_list[type_of_training], markersize = '11', markerfacecolor = 'None', markeredgecolor = color_list[n_hidden_units][architecture], markevery = int(len_training_loss/10), color = color_list[n_hidden_units][architecture])\n",
    "\n",
    "                    x_max = x_lim[1] if x_lim is not None else validation_loss[:,0][-1]*observation_rate\n",
    "                    len_validation_loss = len(validation_loss[validation_loss[:,0] < x_max])\n",
    "                    # plt.errorbar(validation_loss[:,0], validation_loss[:,1], validation_loss_error, marker = marker_list[type_of_training], markersize = '4', markerfacecolor = 'None', markeredgecolor = color_list[n_hidden_units][architecture], markevery = int(len_validation_loss/10), linestyle = ':', color = color_list[n_hidden_units][architecture])\n",
    "                    plt.errorbar(validation_loss[:,0], validation_loss[:,1], marker = marker_list[type_of_training], markersize = '11', markerfacecolor = 'None', markeredgecolor = color_list[n_hidden_units][architecture], markevery = int(len_validation_loss/10), linestyle = ':', color = color_list[n_hidden_units][architecture])\n",
    "\n",
    "                else : \n",
    "                    training_loss = statistical_curve_dictionnary[n_hidden_units][type_of_training][architecture]['mean']['fine tuned training loss']\n",
    "                    training_loss_error = statistical_curve_dictionnary[n_hidden_units][type_of_training][architecture]['error']['fine tuned training loss']\n",
    "                    x_max = x_lim[1] if x_lim is not None else training_loss[:,0][-1]*observation_rate\n",
    "                    len_training_loss = len(training_loss[training_loss[:,0] < x_max])\n",
    "                    plt.errorbar(training_loss[:,0], training_loss[:,1], training_loss_error, marker = marker_list[type_of_training], markersize = '11',\n",
    "                                  markerfacecolor = color_list[n_hidden_units][architecture], markeredgecolor = color_list[n_hidden_units][architecture], \n",
    "                                  markevery = int(len_validation_loss/10), color = color_list[n_hidden_units][architecture])\n",
    "                    x_max = x_lim[1] if x_lim is not None else validation_loss[:,0][-1]*observation_rate\n",
    "                    len_training_loss = len(validation_loss[validation_loss[:,0] < x_max])\n",
    "                    validation_loss = statistical_curve_dictionnary[n_hidden_units][type_of_training][architecture]['mean']['fine tuned validation loss']\n",
    "                    validation_loss_error = statistical_curve_dictionnary[n_hidden_units][type_of_training][architecture]['error']['fine tuned validation loss']\n",
    "                    plt.errorbar(validation_loss[:,0], validation_loss[:,1], validation_loss_error, marker = marker_list[type_of_training], markersize = '11',\n",
    "                                  markerfacecolor = color_list[n_hidden_units][architecture], markevery = int(len_validation_loss/10), \n",
    "                                  \n",
    "                                  markeredgecolor = color_list[n_hidden_units][architecture], linestyle = ':', color = color_list[n_hidden_units][architecture])\n",
    "    labels=[]\n",
    "    legend_hu = []\n",
    "    legend_training_type = []\n",
    "    legend_loss_type = [Line2D([0], [0], color = 'black', label = 'Training loss'), \n",
    "                        Line2D([0], [0], color = 'black', linestyle = ':', label = 'Validation_loss')]\n",
    "    for i, n_hidden_units in enumerate(statistical_curve_dictionnary):\n",
    "        for j, type_of_training in enumerate(statistical_curve_dictionnary[n_hidden_units]): \n",
    "            for k, architecture in enumerate(statistical_curve_dictionnary[n_hidden_units][type_of_training]):\n",
    "                if i == 0 and k == 0:\n",
    "                    if type_of_training != 'First trained + Last fine tuned' :\n",
    "                        legend_training_type += [Line2D([0], [0], markeredgecolor = 'black', markerfacecolor = 'None', marker = marker_list[type_of_training], linestyle='None', label = type_of_training)]\n",
    "                    else : \n",
    "                        legend_training_type += [Line2D([0], [0], markeredgecolor = 'black', markerfacecolor = 'black', marker = marker_list[type_of_training], linestyle='None', label = type_of_training)]\n",
    "                if np.sum([n_hidden_units + ' - ' + architecture==label for label in labels])==0:    \n",
    "                    legend_hu += [Line2D([0], [0], color = color_list[n_hidden_units][architecture], linewidth=5, label = n_hidden_units + ' - ' + architecture)]\n",
    "                    labels += [n_hidden_units + ' - ' + architecture]\n",
    "    legend_elements = legend_loss_type + legend_hu + legend_training_type\n",
    "    legend = plt.legend(handles=legend_elements, loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    for handle in legend.legend_handles:\n",
    "        handle.set_markersize(15)\n",
    "    plt.xlabel('Number of iterations')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title(f'Mean loss during training for \\nthe different architectures and types of training\\non N = {n_saves} samples', pad = 20)\n",
    "    x_max = np.max([np.max(statistical_curve_dictionnary[n_hidden_units][type_of_training][architecture]['mean']['training loss'][:,0])\n",
    "                    for n_hidden_units in statistical_curve_dictionnary\n",
    "                    for type_of_training in statistical_curve_dictionnary[n_hidden_units]\n",
    "                    for architecture in statistical_curve_dictionnary[n_hidden_units][type_of_training]]) if x_lim == None else x_lim[1]\n",
    "    plt.xlim(0, x_max)\n",
    "    y_max = np.max([np.max(statistical_curve_dictionnary[n_hidden_units][type_of_training][architecture]['mean']['training loss'][:,1]) \n",
    "                for n_hidden_units in statistical_curve_dictionnary\n",
    "                for type_of_training in statistical_curve_dictionnary[n_hidden_units]\n",
    "                for architecture in statistical_curve_dictionnary[n_hidden_units][type_of_training]]\n",
    "                + [np.max(statistical_curve_dictionnary[n_hidden_units][type_of_training][architecture]['mean']['validation loss'][:,1])\n",
    "                for n_hidden_units in statistical_curve_dictionnary\n",
    "                for type_of_training in statistical_curve_dictionnary[n_hidden_units]\n",
    "                for architecture in statistical_curve_dictionnary[n_hidden_units][type_of_training]]) if y_lim == None else y_lim[1]    \n",
    "    plt.ylim(-0.01, y_max + 0.01)\n",
    "    plt.grid()\n",
    "    if save :\n",
    "        plt.savefig(save_path + 'loss_trajectories' + save_name_peculiarity + '.png', bbox_inches='tight')\n",
    "        plt.savefig(save_path + 'loss_trajectories' + save_name_peculiarity + '.svg', bbox_inches='tight')\n",
    "    plt.show()  \n",
    "    return\n",
    "\n",
    "\n",
    "### STATISTICAL MAXIMUM ACCURACY ###\n",
    "\n",
    "def statistical_max_accuracy_plot(multi_save_data_dictionnary, color_list, marker_list, save_file=True, save_path = '', save_name_peculiarity='') :\n",
    "    x_list = {'2 layers' : 2, '3 layers' : 3, '4 layers' : 4}\n",
    "    max_accuracy_dictionnary = deepcopy(multi_save_data_dictionnary)\n",
    "    for n_hidden_units in multi_save_data_dictionnary:\n",
    "        for type_of_training in multi_save_data_dictionnary[n_hidden_units] :\n",
    "            for architecture in multi_save_data_dictionnary[n_hidden_units][type_of_training]:\n",
    "                if type_of_training != 'First trained + Last fine tuned' :\n",
    "                    max_accuracy_dictionnary[n_hidden_units][type_of_training][architecture]['mean'] = np.mean([np.max(multi_save_data_dictionnary[n_hidden_units][type_of_training][architecture][save]['accuracy'][:,1]) for save in multi_save_data_dictionnary[n_hidden_units][type_of_training][architecture]])\n",
    "                    max_accuracy_dictionnary[n_hidden_units][type_of_training][architecture]['error'] = np.sqrt(np.mean([(max_accuracy_dictionnary[n_hidden_units][type_of_training][architecture]['mean'] - np.max(multi_save_data_dictionnary[n_hidden_units][type_of_training][architecture][save]['accuracy'][:,1]))**2 for save in multi_save_data_dictionnary[n_hidden_units][type_of_training][architecture]]))\n",
    "                    plt.errorbar(x_list[architecture], max_accuracy_dictionnary[n_hidden_units][type_of_training][architecture]['mean'], \n",
    "                                 yerr=max_accuracy_dictionnary[n_hidden_units][type_of_training][architecture]['error'], fmt=marker_list[type_of_training], \n",
    "                                 ecolor = color_list[n_hidden_units], capsize=2,\n",
    "                                 markersize = '11', markerfacecolor = 'None', markeredgecolor = color_list[n_hidden_units])\n",
    "                    \n",
    "                else : \n",
    "                    max_accuracy_dictionnary[n_hidden_units][type_of_training][architecture]['mean'] = np.mean([np.max(multi_save_data_dictionnary[n_hidden_units][type_of_training][architecture][save]['fine tuned accuracy'][:,1]) for save in multi_save_data_dictionnary[n_hidden_units][type_of_training][architecture]])\n",
    "                    max_accuracy_dictionnary[n_hidden_units][type_of_training][architecture]['error'] = np.sqrt(np.mean([(max_accuracy_dictionnary[n_hidden_units][type_of_training][architecture]['mean'] - np.max(multi_save_data_dictionnary[n_hidden_units][type_of_training][architecture][save]['fine tuned accuracy'][:,1]))**2 for save in multi_save_data_dictionnary[n_hidden_units][type_of_training][architecture]]))\n",
    "                    plt.errorbar(x_list[architecture], max_accuracy_dictionnary[n_hidden_units][type_of_training][architecture]['mean'], \n",
    "                                 yerr=max_accuracy_dictionnary[n_hidden_units][type_of_training][architecture]['error'], fmt=marker_list[type_of_training], \n",
    "                                 ecolor = color_list[n_hidden_units], capsize=2,\n",
    "                                 markersize = '11', markerfacecolor = color_list[n_hidden_units], markeredgecolor = color_list[n_hidden_units])\n",
    "\n",
    "    legend_hu = []\n",
    "    legend_training_type = []\n",
    "    for i, n_hidden_units in enumerate(max_accuracy_dictionnary):\n",
    "        legend_hu += [Line2D([0], [0], color = color_list[n_hidden_units], marker = '.', linestyle='None', label = n_hidden_units)]\n",
    "        if i == 0:\n",
    "            for type_of_training in max_accuracy_dictionnary[n_hidden_units]:\n",
    "                if type_of_training != 'First trained + Last fine tuned' :\n",
    "                    legend_training_type += [Line2D([0], [0], markeredgecolor = 'black', markerfacecolor = 'None', marker = marker_list[type_of_training], linestyle='None', label = type_of_training)]\n",
    "                else : \n",
    "                    legend_training_type += [Line2D([0], [0], markeredgecolor = 'black', markerfacecolor = 'black', marker = marker_list[type_of_training], linestyle='None', label = type_of_training)]\n",
    "    legend_elements = legend_hu + legend_training_type\n",
    "    legend = plt.legend(handles=legend_elements, loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    for handle in legend.legend_handles:\n",
    "        handle.set_markersize(15)\n",
    "    plt.xlabel('Number of layers')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title(f'Mean maximum accuracy for\\n the different architectures and types of training\\non N = {len(multi_save_data_dictionnary[n_hidden_units][type_of_training][architecture])} samples', pad = 20)\n",
    "    y_max = np.max([max_accuracy_dictionnary[n_hidden_units][type_of_training][architecture]['mean'] \n",
    "                for n_hidden_units in max_accuracy_dictionnary\n",
    "                for type_of_training in max_accuracy_dictionnary[n_hidden_units]\n",
    "                for architecture in max_accuracy_dictionnary[n_hidden_units][type_of_training]])\n",
    "    y_min = np.min([max_accuracy_dictionnary[n_hidden_units][type_of_training][architecture]['mean'] \n",
    "                for n_hidden_units in max_accuracy_dictionnary\n",
    "                for type_of_training in max_accuracy_dictionnary[n_hidden_units]\n",
    "                for architecture in max_accuracy_dictionnary[n_hidden_units][type_of_training]])\n",
    "    plt.ylim(y_min - 0.01, y_max + 0.01)\n",
    "    plt.xticks([x for key, x in x_list.items()])\n",
    "    plt.grid()\n",
    "    if save_file :\n",
    "        plt.savefig(save_path + 'max_accuracy_' + save_name_peculiarity + '.png', bbox_inches='tight')\n",
    "        plt.savefig(save_path + 'max_accuracy_' + save_name_peculiarity + '.svg', bbox_inches='tight')\n",
    "    plt.show()  \n",
    "    return\n",
    "\n",
    "\n",
    "    ## As a function of kappa = log(n)/log(d) ##\n",
    "\n",
    "def statistical_kappa_max_accuracy_plot(multi_kappa_multi_save_data_dictionnary, color_list, marker_list, save_file=True, save_path = '', save_name_peculiarity='') :    \n",
    "    max_accuracy_dictionnary = deepcopy(multi_kappa_multi_save_data_dictionnary)\n",
    "    for n_hidden_units in multi_kappa_multi_save_data_dictionnary:\n",
    "        for type_of_training in multi_kappa_multi_save_data_dictionnary[n_hidden_units] :\n",
    "            for architecture in multi_kappa_multi_save_data_dictionnary[n_hidden_units][type_of_training]:\n",
    "                x_list = [int(kappa[8:]) for kappa in multi_kappa_multi_save_data_dictionnary[n_hidden_units][type_of_training]]\n",
    "                for kappa in multi_kappa_multi_save_data_dictionnary[n_hidden_units][type_of_training][architecture]: \n",
    "                    if type_of_training != 'First trained + Last fine tuned' :\n",
    "                        max_accuracy_dictionnary[n_hidden_units][type_of_training][architecture][kappa]['mean'] = np.mean([np.max(multi_kappa_multi_save_data_dictionnary[n_hidden_units][type_of_training][architecture][kappa][save]['accuracy'][:,1]) \n",
    "                                                                                                                           for save in multi_kappa_multi_save_data_dictionnary[n_hidden_units][type_of_training][architecture][kappa]])\n",
    "                        max_accuracy_dictionnary[n_hidden_units][type_of_training][architecture][kappa]['error'] = np.sqrt(np.mean([(max_accuracy_dictionnary[n_hidden_units][type_of_training][architecture][kappa]['mean'] \n",
    "                                                                                                                                     - np.max(multi_kappa_multi_save_data_dictionnary[n_hidden_units][type_of_training][architecture][kappa][save]['accuracy'][:,1]))**2 \n",
    "                                                                                                                                     for save in multi_kappa_multi_save_data_dictionnary[n_hidden_units][type_of_training][architecture][kappa]]))\n",
    "                        \n",
    "                    else : \n",
    "                        max_accuracy_dictionnary[n_hidden_units][type_of_training][architecture][kappa]['mean'] = np.mean([np.max(multi_kappa_multi_save_data_dictionnary[n_hidden_units][type_of_training][architecture][kappa][save]['fine tuned accuracy'][:,1])\n",
    "                                                                                                                                    for save in multi_kappa_multi_save_data_dictionnary[n_hidden_units][type_of_training][architecture][kappa]])\n",
    "                        max_accuracy_dictionnary[n_hidden_units][type_of_training][architecture][kappa]['error'] = np.sqrt(np.mean([(max_accuracy_dictionnary[n_hidden_units][type_of_training][architecture][kappa]['mean']\n",
    "                                                                                                                                      - np.max(multi_kappa_multi_save_data_dictionnary[n_hidden_units][type_of_training][architecture][kappa][save]['fine tuned accuracy'][:,1]))**2\n",
    "                                                                                                                                     for save in multi_kappa_multi_save_data_dictionnary[n_hidden_units][type_of_training][architecture][kappa]]))\n",
    "                                    \n",
    "                if type_of_training != 'First trained + Last fine tuned' :\n",
    "                    plt.errorbar(x_list, max_accuracy_dictionnary[n_hidden_units][type_of_training][architecture][:]['mean'], \n",
    "                                                    yerr=max_accuracy_dictionnary[n_hidden_units][type_of_training][architecture][:]['error'], fmt=marker_list[type_of_training], \n",
    "                                                    ecolor = color_list[n_hidden_units], capsize=2,\n",
    "                                                    markersize = '11', markerfacecolor = 'None', markeredgecolor = color_list[n_hidden_units])\n",
    "                \n",
    "                else :\n",
    "                    plt.errorbar(x_list[architecture], max_accuracy_dictionnary[n_hidden_units][type_of_training][architecture][:]['mean'], \n",
    "                                yerr=max_accuracy_dictionnary[n_hidden_units][type_of_training][architecture][:]['error'], fmt=marker_list[type_of_training], \n",
    "                                ecolor = color_list[n_hidden_units], capsize=2,\n",
    "                                markersize = '11', markerfacecolor = color_list[n_hidden_units], markeredgecolor = color_list[n_hidden_units])\n",
    "\n",
    "    legend_hu = []\n",
    "    legend_training_type = []\n",
    "    for i, n_hidden_units in enumerate(max_accuracy_dictionnary):\n",
    "        legend_hu += [Line2D([0], [0], color = color_list[n_hidden_units], marker = '.', linestyle='None', label = n_hidden_units)]\n",
    "        if i == 0:\n",
    "            for type_of_training in max_accuracy_dictionnary[n_hidden_units]:\n",
    "                if type_of_training != 'First trained + Last fine tuned' :\n",
    "                    legend_training_type += [Line2D([0], [0], markeredgecolor = 'black', markerfacecolor = 'None', marker = marker_list[type_of_training], linestyle='None', label = type_of_training)]\n",
    "                else : \n",
    "                    legend_training_type += [Line2D([0], [0], markeredgecolor = 'black', markerfacecolor = 'black', marker = marker_list[type_of_training], linestyle='None', label = type_of_training)]\n",
    "    legend_elements = legend_hu + legend_training_type\n",
    "    legend = plt.legend(handles=legend_elements, loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    for handle in legend.legend_handles:\n",
    "        handle.set_markersize(15)\n",
    "    plt.xlabel('Number of layers')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title(f'Mean maximum accuracy for\\n the different architectures and types of training\\ndepending on the number of datas\\non N = {len(multi_kappa_multi_save_data_dictionnary[n_hidden_units][type_of_training][architecture][kappa])} samples', pad = 20)\n",
    "    y_max = np.max([max_accuracy_dictionnary[n_hidden_units][type_of_training][architecture][kappa]['mean'] \n",
    "                for n_hidden_units in max_accuracy_dictionnary\n",
    "                for type_of_training in max_accuracy_dictionnary[n_hidden_units]\n",
    "                for architecture in max_accuracy_dictionnary[n_hidden_units][type_of_training]\n",
    "                for kappa in max_accuracy_dictionnary[n_hidden_units][type_of_training][architecture]])\n",
    "    y_min = np.min([max_accuracy_dictionnary[n_hidden_units][type_of_training][architecture][kappa]['mean'] \n",
    "                for n_hidden_units in max_accuracy_dictionnary\n",
    "                for type_of_training in max_accuracy_dictionnary[n_hidden_units]\n",
    "                for architecture in max_accuracy_dictionnary[n_hidden_units][type_of_training]\n",
    "                for kappa in max_accuracy_dictionnary[n_hidden_units][type_of_training][architecture]])\n",
    "    plt.ylim(y_min - 0.01, y_max + 0.01)\n",
    "    plt.xticks([x for key, x in x_list.items()])\n",
    "    plt.grid()\n",
    "    if save_file :\n",
    "        plt.savefig(save_path + 'max_accuracy_depending_on_kappa_' + save_name_peculiarity + '.png', bbox_inches='tight')\n",
    "        plt.savefig(save_path + 'max_accuracy_depending_on_kappa_' + save_name_peculiarity + '.svg', bbox_inches='tight')\n",
    "    plt.show()  \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Features overlap during training ###\n",
    "\n",
    "def layer_representation(weight_1, bias_1, weight_2, bias_2, inputs, deep_layer_inputs, type, layer_rank):\n",
    "    if layer_rank==1 :\n",
    "        if type == 'preactivation':\n",
    "            layer_1 = torch.einsum('pdt,nd->pnt', weight_1, inputs) + bias_1 # shape (d1, n)\n",
    "            layer_2 = torch.einsum('pdt,nd->pnt', weight_2, inputs) + bias_2 # shape (d1, n)   \n",
    "        elif type == 'hidden' :\n",
    "            layer_1 = torch.relu(torch.einsum('pdt,nd->pnt', weight_1, inputs) + bias_1) # shape (d1, n, t)\n",
    "            layer_2 = torch.relu(torch.einsum('pdt,nd->pnt', weight_2, inputs) + bias_2) # shape (d1, n, t)\n",
    "    else :\n",
    "        if type == 'preactivation':\n",
    "            layer_1 = torch.einsum('qpt,pnt->qnt', weight_1, deep_layer_inputs[0]) + bias_1 # shape (d1, n)\n",
    "            layer_2 = torch.einsum('qpt,pnt->qnt', weight_2, deep_layer_inputs[1]) + bias_2 # shape (d1, n)   \n",
    "        elif type == 'hidden' :\n",
    "            layer_1 = torch.relu(torch.einsum('qpt,pnt->qnt', weight_1, deep_layer_inputs[0]) + bias_1) # shape (d1, n, t)\n",
    "            layer_2 = torch.relu(torch.einsum('qpt,pnt->qnt', weight_2, deep_layer_inputs[1]) + bias_2) # shape (d1, n, t)\n",
    "\n",
    "    column_norm_layer_1 = layer_1.norm(dim=0).unsqueeze(0) # shape (1,n,t)\n",
    "    column_norm_layer_2 = layer_2.norm(dim=0).unsqueeze(0)  # shape (1,n,t)\n",
    "    norm_cross_matrix_layer = torch.einsum('int,imt->nmt', column_norm_layer_1, column_norm_layer_2) # shape (n,n,t)\n",
    "    cross_scalar_product_matrix_layer = torch.einsum('qnt,qmt->nmt', layer_1, layer_2)\n",
    "    \n",
    "    normalized_cross_scalar_product_matrix_layer = (cross_scalar_product_matrix_layer / norm_cross_matrix_layer)\n",
    "    return normalized_cross_scalar_product_matrix_layer, layer_1, layer_2\n",
    "\n",
    "def representation_overlap_trajectories(model_1, model_2, x_validation, save_path, architecture, add_to_title=''):\n",
    "    x_validation = x_validation.to(device)\n",
    "    min_time = np.min([len(model_1['layers trajectories'][1]), len(model_2['layers trajectories'][1])])\n",
    "    print(min_time)\n",
    "    \n",
    "    overlap_dico = {'normalized_cross_scalar_product_matrix_trace_trajectory' : \n",
    "        {'data' : {1 : {'preactivation' : [], 'hidden' : []}, 2 : {'preactivation' : [], 'hidden' : []}}, \n",
    "         'plot' : {'title' : 'Expectation of the cosine similarity between the representations\\nof ' + add_to_title,\n",
    "                   'xlabel' : 'Iteration N', 'ylabel' : r\"$\\mathbb{E}_{\\bf{x}}[\\cos(\\theta)]$\"}},\n",
    "                    'cross_scalar_product_matrix_trace_variance_trajectory' :\n",
    "        {'data' : {1 : {'preactivation' : [], 'hidden' : []}, 2 : {'preactivation' : [], 'hidden' : []}},\n",
    "         'plot' : {'title' : 'Variance of the cosine similarity between the representations\\nof ' + add_to_title,\n",
    "                   'xlabel' : 'Iteration N', 'ylabel' : r\"Var [$\\cos(\\theta)$]\"}},\n",
    "                    'arccos_product_matrix_trace_trajectory' :\n",
    "        {'data' : {1 : {'preactivation' : [], 'hidden' : []}, 2 : {'preactivation' : [], 'hidden' : []}},\n",
    "         'plot' : {'title' : 'Mean angle between the representations\\nof ' + add_to_title,\n",
    "                   'xlabel' : 'Iteration N', 'ylabel' : r\"$\\theta$\"}},\n",
    "                    'max_normalized_cross_scalar_product_matrix_trace_trajectory' :\n",
    "        {'data' : {1 : {'preactivation' : [], 'hidden' : []}, 2 : {'preactivation' : [], 'hidden' : []}},\n",
    "         'plot' : {'title' : 'Maximum cosine similarity between the representations\\n of ' + add_to_title,\n",
    "                   'xlabel' : 'Iteration N', 'ylabel' : r\"Max ($[\\cos(\\theta))$]\"}}}\n",
    "\n",
    "    normalized_cross_scalar_product_matrix = {1 : {'preactivation' : [], 'hidden' : []}, 2 : {'preactivation' : [], 'hidden' : []}}\n",
    "    color_list = {1 : {'preactivation' : 'blue', 'hidden' : 'green'}, 2 : {'preactivation' : 'orange', 'hidden' : 'red'}}\n",
    "\n",
    "    label_list = {1 : {'preactivation' : r\"$(W_1.x^{\\top})^{\\top}.(W_1'.x^{\\top})$\", 'hidden' : r\"$(\\sigma(W_1.x^{\\top}))^{\\top}.(\\sigma(W_1'.x^{\\top}))$\"},\n",
    "                  2 : {'preactivation' : r\"$(W_2\\sigma(W_1.x^{\\top}))^{\\top}.(W_2'\\sigma(W_1'.x^{\\top}))$\", 'hidden' : r\"$(\\sigma(W_2\\sigma(W_1.x^{\\top})))^{\\top}.(\\sigma(W_2'\\sigma(W_1'.x^{\\top})))$\"}}\n",
    "    for first_layer_params_1, first_layer_params_2, second_layer_params_1, second_layer_params_2 in zip(model_1['layers trajectories'][1][:min_time],\n",
    "                                                                                                        model_2['layers trajectories'][1][:min_time], \n",
    "                                                                                                        model_1['layers trajectories'][2][:min_time],\n",
    "                                                                                                        model_2['layers trajectories'][2][:min_time]) :\n",
    "        \n",
    "        weights = {'model 1' : {1 : first_layer_params_1[:,:-1,:].to(device), 2 : second_layer_params_1[:,:-1,:].to(device)}, \n",
    "                   'model 2' : {1 : first_layer_params_2[:,:-1,:].to(device), 2 : second_layer_params_2[:,:-1,:].to(device)}}\n",
    "        biases = {'model 1' : {1 : first_layer_params_1[:,-1,:].to(device).unsqueeze(1), 2 : second_layer_params_1[:,-1,:].to(device).unsqueeze(1)}, \n",
    "                'model 2' : {1 : first_layer_params_2[:,-1,:].to(device).unsqueeze(1), 2 : second_layer_params_2[:,-1,:].to(device).unsqueeze(1)}}\n",
    "\n",
    "        for layer_rank in normalized_cross_scalar_product_matrix :\n",
    "            if layer_rank == 1:\n",
    "                deep_layer_inputs = []\n",
    "                normalized_cross_scalar_product_matrix[layer_rank]['preactivation'] = layer_representation(\n",
    "                    weights['model 1'][layer_rank], biases['model 1'][layer_rank], weights['model 2'][layer_rank], \n",
    "                    biases['model 2'][layer_rank], x_validation, deep_layer_inputs, type='preactivation', layer_rank=layer_rank)[0]\n",
    "\n",
    "                normalized_cross_scalar_product_matrix[layer_rank]['hidden'], layer_1, layer_2 = layer_representation(\n",
    "                    weights['model 1'][layer_rank], biases['model 1'][layer_rank], weights['model 2'][layer_rank],\n",
    "                    biases['model 2'][layer_rank], x_validation, deep_layer_inputs, type='hidden', layer_rank=layer_rank)\n",
    "\n",
    "            else :\n",
    "                deep_layer_inputs = [layer_1, layer_2]\n",
    "                normalized_cross_scalar_product_matrix[layer_rank]['preactivation'] = layer_representation(\n",
    "                    weights['model 1'][layer_rank], biases['model 1'][layer_rank], weights['model 2'][layer_rank], \n",
    "                    biases['model 2'][layer_rank], x_valid, deep_layer_inputs, type='preactivation', layer_rank=layer_rank)[0]\n",
    "\n",
    "                normalized_cross_scalar_product_matrix[layer_rank]['hidden'], layer_1, layer_2 = layer_representation(\n",
    "                    weights['model 1'][layer_rank], biases['model 1'][layer_rank], weights['model 2'][layer_rank],\n",
    "                    biases['model 2'][layer_rank], x_valid, deep_layer_inputs, type='hidden', layer_rank=layer_rank)\n",
    "            \n",
    "\n",
    "        save_interval_size = normalized_cross_scalar_product_matrix[layer_rank]['preactivation'].shape[2]\n",
    "        # Register overlap information\n",
    "        for t in range (save_interval_size): \n",
    "            for layer_rank in overlap_dico['normalized_cross_scalar_product_matrix_trace_trajectory']['data'] :\n",
    "                for type_of_layer in overlap_dico['normalized_cross_scalar_product_matrix_trace_trajectory']['data'][layer_rank] :\n",
    "                    # First layer preactivation \n",
    "                    overlap_dico['normalized_cross_scalar_product_matrix_trace_trajectory']['data'][layer_rank][type_of_layer].append(normalized_cross_scalar_product_matrix[layer_rank][type_of_layer][:,:,t].trace().cpu()/x_validation.shape[0])\n",
    "                    overlap_dico['max_normalized_cross_scalar_product_matrix_trace_trajectory']['data'][layer_rank][type_of_layer].append(normalized_cross_scalar_product_matrix[layer_rank][type_of_layer][:,:,t].max().cpu()) \n",
    "                    overlap_dico['arccos_product_matrix_trace_trajectory']['data'][layer_rank][type_of_layer].append((180/np.pi)*np.arccos(normalized_cross_scalar_product_matrix[layer_rank][type_of_layer][:,:,t].trace().cpu()/x_validation.shape[0]))\n",
    "                    overlap_dico['cross_scalar_product_matrix_trace_variance_trajectory']['data'][layer_rank][type_of_layer].append((torch.sqrt((normalized_cross_scalar_product_matrix[layer_rank][type_of_layer][:,:,t] - (normalized_cross_scalar_product_matrix[layer_rank][type_of_layer][:,:,t].trace()/x_validation.shape[0]))**2).mean()).cpu())\n",
    "    \n",
    "    # Plot datas\n",
    "    \n",
    "    T = np.linspace(0, (min_time*save_interval_size+1)*10, min_time*save_interval_size+1)\n",
    "    for curve in overlap_dico :\n",
    "        legend_elements = []\n",
    "        for layer_rank in overlap_dico[curve]['data']:\n",
    "            for type_of_layer in overlap_dico[curve]['data'][layer_rank]:\n",
    "                plt.plot(T, overlap_dico[curve]['data'][layer_rank][type_of_layer], color=color_list[layer_rank][type_of_layer])\n",
    "                legend_elements += [Line2D([0], [0], color=color_list[layer_rank][type_of_layer], linewidth=5, label = label_list[layer_rank][type_of_layer])]                    \n",
    "        legend = plt.legend(handles=legend_elements, loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "        for handle in legend.legend_handles:\n",
    "            handle.set_markersize(15)\n",
    "        plt.title(overlap_dico[curve]['plot']['title'], pad=20)\n",
    "        plt.xlabel(overlap_dico[curve]['plot']['xlabel'])\n",
    "        plt.ylabel(overlap_dico[curve]['plot']['ylabel'])\n",
    "        if curve == 'normalized_cross_scalar_product_matrix_trace_trajectory' or curve == 'max_normalized_cross_scalar_product_matrix_trace_trajectory':\n",
    "            plt.ylim([-0.05,0.5])\n",
    "        elif curve == 'arccos_product_matrix_trace_trajectory':\n",
    "            plt.ylim([60,95])\n",
    "        plt.grid()\n",
    "        os.makedirs(save_path + '/' + architecture, exist_ok=True) \n",
    "        plt.savefig(save_path + '/' + architecture + '/' + curve + '.png', bbox_inches='tight')\n",
    "        plt.savefig(save_path + '/' + architecture + '/' + curve + '.svg', bbox_inches='tight')\n",
    "        plt.show()\n",
    "\n",
    "    return overlap_dico\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer_representation(weight_1, bias_1, weight_2, bias_2, inputs, deep_layer_inputs, type, layer_rank):\n",
    "    if layer_rank==1 :\n",
    "        if type == 'preactivation':\n",
    "            layer_1 = torch.einsum('pdt,nd->pnt', weight_1, inputs) + bias_1 # shape (d1, n)\n",
    "            layer_2 = torch.einsum('pdt,nd->pnt', weight_2, inputs) + bias_2 # shape (d1, n)   \n",
    "        elif type == 'hidden' :\n",
    "            layer_1 = torch.relu(torch.einsum('pdt,nd->pnt', weight_1, inputs) + bias_1) # shape (d1, n, t)\n",
    "            layer_2 = torch.relu(torch.einsum('pdt,nd->pnt', weight_2, inputs) + bias_2) # shape (d1, n, t)\n",
    "    else :\n",
    "        if type == 'preactivation':\n",
    "            layer_1 = torch.einsum('qpt,pnt->qnt', weight_1, deep_layer_inputs[0]) + bias_1 # shape (d1, n)\n",
    "            layer_2 = torch.einsum('qpt,pnt->qnt', weight_2, deep_layer_inputs[1]) + bias_2 # shape (d1, n)   \n",
    "        elif type == 'hidden' :\n",
    "            layer_1 = torch.relu(torch.einsum('qpt,pnt->qnt', weight_1, deep_layer_inputs[0]) + bias_1) # shape (d1, n, t)\n",
    "            layer_2 = torch.relu(torch.einsum('qpt,pnt->qnt', weight_2, deep_layer_inputs[1]) + bias_2) # shape (d1, n, t)\n",
    "\n",
    "    column_norm_layer_1 = layer_1.norm(dim=0).unsqueeze(0) # shape (1,n,t)\n",
    "    column_norm_layer_2 = layer_2.norm(dim=0).unsqueeze(0)  # shape (1,n,t)\n",
    "    norm_cross_matrix_layer = torch.einsum('int,imt->nmt', column_norm_layer_1, column_norm_layer_2) # shape (n,n,t)\n",
    "    cross_scalar_product_matrix_layer = torch.einsum('qnt,qmt->nmt', layer_1, layer_2)\n",
    "    \n",
    "    normalized_cross_scalar_product_matrix_layer = (cross_scalar_product_matrix_layer / norm_cross_matrix_layer)\n",
    "    return normalized_cross_scalar_product_matrix_layer, layer_1, layer_2\n",
    "\n",
    "def layers_covariances(weight_1, bias_1, weight_2, bias_2, inputs, deep_layer_inputs, type, layer_rank):\n",
    "    if layer_rank==1:    \n",
    "        \n",
    "        if type == 'preactivation matrix':\n",
    "            layer_1, layer_2 = torch.cat([weight_1,bias_1], dim=1), torch.cat([weight_2,bias_2], dim=1) # shape (d1,d+1,t)\n",
    "            norm = layer_1.norm(dim=(0,1))*layer_2.norm(dim=(0,1))  # shape (1,1,t)\n",
    "            covariance_matrix = torch.einsum('qdt,pdt->qpt', layer_1, layer_2) # shape (d1,d1, t)\n",
    "        elif type == 'preactivation representation':\n",
    "            layer_1 = torch.relu(torch.einsum('pdt,nd->pnt', weight_1, inputs) + bias_1) # shape (d1, n)\n",
    "            layer_2 = torch.relu(torch.einsum('pdt,nd->pnt', weight_2, inputs) + bias_2) # shape (d1, n)\n",
    "            norm = layer_1.norm(dim=(0,1))*layer_2.norm(dim=(0,1))  # shape (1,1,t)\n",
    "            covariance_matrix = torch.einsum('qnt,pnt->qpt', layer_1, layer_2) # shape (d1,d1, t)\n",
    "        elif type == 'hidden matrix' :\n",
    "            layer_1, layer_2 = torch.relu(torch.cat([weight_1,bias_1], dim=1)), torch.relu(torch.cat([weight_2,bias_2], dim=1)) # shape (d1,d+1,t)\n",
    "            norm = layer_1.norm(dim=(0,1))*layer_2.norm(dim=(0,1))  # shape (1,1,t)\n",
    "            covariance_matrix = torch.einsum('qdt,pdt->qpt', layer_1, layer_2) # shape (d1,d1, t)\n",
    "        elif type == 'hidden representation' :\n",
    "            layer_1 = torch.relu(torch.einsum('pdt,nd->pnt', weight_1, inputs) + bias_1) # shape (d1, n)\n",
    "            layer_2 = torch.relu(torch.einsum('pdt,nd->pnt', weight_2, inputs) + bias_2) # shape (d1, n)\n",
    "            norm = layer_1.norm(dim=(0,1))*layer_2.norm(dim=(0,1))  # shape (1,1,t)\n",
    "            covariance_matrix = torch.einsum('qnt,pnt->qpt', layer_1, layer_2) # shape (d1,d1, t)\n",
    "    else :\n",
    "        \n",
    "        if type == 'preactivation':\n",
    "            layer_1 = torch.einsum('qpt,pnt->qnt', weight_1, deep_layer_inputs[0]) + bias_1 # shape (d1, n)\n",
    "            layer_2 = torch.einsum('qpt,pnt->qnt', weight_2, deep_layer_inputs[1]) + bias_2 # shape (d1, n)   \n",
    "            norm = layer_1.norm(dim=(0,1))*layer_2.norm(dim=(0,1))  # shape (1,1,t)\n",
    "            covariance_matrix = torch.einsum('qnt,pnt->qpt', layer_1, layer_2) # shape (d1,d1, t)    \n",
    "        elif type == 'hidden' :\n",
    "            layer_1 = torch.relu(torch.einsum('qpt,pnt->qnt', weight_1, deep_layer_inputs[0]) + bias_1) # shape (d1, n, t)\n",
    "            layer_2 = torch.relu(torch.einsum('qpt,pnt->qnt', weight_2, deep_layer_inputs[1]) + bias_2) # shape (d1, n, t)\n",
    "            norm = layer_1.norm(dim=(0,1))*layer_2.norm(dim=(0,1))  # shape (1,1,t)\n",
    "            covariance_matrix = torch.einsum('qnt,pnt->qpt', layer_1, layer_2) # shape (d1,d1,t)\n",
    "    \n",
    "    likelyhood = (covariance_matrix / norm).norm(dim=(0,1)) # shape (t)\n",
    "    return likelyhood, layer_1, layer_2\n",
    "\n",
    "\n",
    "def representations_likelyhood_trajectories(model_1, model_2, x_validation, save_path, architecture, add_to_title=''):\n",
    "    x_validation = x_validation.to(device)\n",
    "    min_time = np.min([len(model_1['layers trajectories'][1]), len(model_2['layers trajectories'][1])])\n",
    "    print(min_time)\n",
    "    \n",
    "    overlap_dico = {'likelyhood_trajectory' : \n",
    "        {'data' : {1 : {'preactivation matrix' : [], 'preactivation representation' : [], 'hidden matrix' : [], 'hidden representation' : []}, \n",
    "                   2 : {'preactivation' : [], 'hidden' : []}}, \n",
    "         'plot' : {'title' : 'Frobenius norm of the covariance matrix between the representations\\nof ' + add_to_title,\n",
    "                   'xlabel' : 'Iteration N', 'ylabel' : r\"$\\mathbb{E}_{\\bf{x}}[\\cos(\\theta)]$\"}},\n",
    "                    'likelyhood_variance_trajectory' :\n",
    "        {'data' : {1 : {'preactivation matrix' : [], 'preactivation representation' : [], 'hidden matrix' : [], 'hidden representation' : []}, \n",
    "                   2 : {'preactivation' : [], 'hidden' : []}},\n",
    "         'plot' : {'title' : 'Variance of the likelyhood between the representations\\nof ' + add_to_title,\n",
    "                   'xlabel' : 'Iteration N', 'ylabel' : r\"Var [$\\cos(\\theta)$]\"}}}\n",
    "\n",
    "    likelyhood = {1 : {'preactivation matrix' : [], 'preactivation representation' : [], 'hidden matrix' : [], 'hidden representation' : []}, \n",
    "                  2 : {'preactivation' : [], 'hidden' : []}}\n",
    "    color_list = {1 : {'preactivation matrix' : 'blue', 'preactivation representation' : 'purple', 'hidden matrix' : 'green', 'hidden representation' : 'gold'}, \n",
    "                  2 : {'preactivation' : 'orange', 'hidden' : 'red'}}\n",
    "\n",
    "    label_list = {1 : {'preactivation matrix' : r\"$\\frac{W_1.W_1'^{\\top}}{\\|W_1\\|_F\\|W_1'\\|_F}$\", 'preactivation representation' : r\"$\\frac{(W_1.x).(W_1'.x)^{\\top}}{\\|W_1.x\\|_F\\|W_1'.x\\|_F}$\", \n",
    "                       'hidden matrix' : r\"$\\frac{(\\sigma(W_1)).(\\sigma(W_1')^{\\top})}{\\|\\sigma(W_1)\\|_F \\|\\sigma(W_1')\\|}$\", 'hidden representation' : r\"$\\frac{(\\sigma(W_1.x^{\\top}))^{\\top}.(\\sigma(W_1'.x^{\\top}))}{\\|\\sigma(W_1.x^{\\top})\\|_F \\|\\sigma(W_1'.x^{\\top})\\|}$\"},\n",
    "                  2 : {'preactivation' : r\"$(W_2\\sigma(W_1.x^{\\top}))^{\\top}.(W_2'\\sigma(W_1'.x^{\\top}))$\", 'hidden' : r\"$(\\sigma(W_2\\sigma(W_1.x^{\\top})))^{\\top}.(\\sigma(W_2'\\sigma(W_1'.x^{\\top})))$\"}}\n",
    "    for first_layer_params_1, first_layer_params_2, second_layer_params_1, second_layer_params_2 in zip(model_1['layers trajectories'][1][:min_time],\n",
    "                                                                                                        model_2['layers trajectories'][1][:min_time], \n",
    "                                                                                                        model_1['layers trajectories'][2][:min_time],\n",
    "                                                                                                        model_2['layers trajectories'][2][:min_time]) :\n",
    "        \n",
    "        weights = {'model 1' : {1 : first_layer_params_1[:,:-1,:].to(device), 2 : second_layer_params_1[:,:-1,:].to(device)}, \n",
    "                   'model 2' : {1 : first_layer_params_2[:,:-1,:].to(device), 2 : second_layer_params_2[:,:-1,:].to(device)}}\n",
    "        biases = {'model 1' : {1 : first_layer_params_1[:,-1,:].to(device).unsqueeze(1), 2 : second_layer_params_1[:,-1,:].to(device).unsqueeze(1)}, \n",
    "                'model 2' : {1 : first_layer_params_2[:,-1,:].to(device).unsqueeze(1), 2 : second_layer_params_2[:,-1,:].to(device).unsqueeze(1)}}\n",
    "\n",
    "        for layer_rank in likelyhood :\n",
    "            if layer_rank == 1:\n",
    "                deep_layer_inputs = []\n",
    "                likelyhood[layer_rank]['preactivation matrix'] = layers_covariances(\n",
    "                    weights['model 1'][layer_rank], biases['model 1'][layer_rank], weights['model 2'][layer_rank], \n",
    "                    biases['model 2'][layer_rank], x_validation, deep_layer_inputs, type='preactivation matrix', layer_rank=layer_rank)[0]\n",
    "                \n",
    "                deep_layer_inputs = []\n",
    "                likelyhood[layer_rank]['preactivation representation'] = layers_covariances(\n",
    "                    weights['model 1'][layer_rank], biases['model 1'][layer_rank], weights['model 2'][layer_rank], \n",
    "                    biases['model 2'][layer_rank], x_validation, deep_layer_inputs, type='preactivation representation', layer_rank=layer_rank)[0]\n",
    "                \n",
    "                deep_layer_inputs = []\n",
    "                likelyhood[layer_rank]['hidden matrix'] = layers_covariances(\n",
    "                    weights['model 1'][layer_rank], biases['model 1'][layer_rank], weights['model 2'][layer_rank], \n",
    "                    biases['model 2'][layer_rank], x_validation, deep_layer_inputs, type='hidden matrix', layer_rank=layer_rank)[0]\n",
    "                \n",
    "                likelyhood[layer_rank]['hidden representation'], layer_1, layer_2 = layers_covariances(\n",
    "                    weights['model 1'][layer_rank], biases['model 1'][layer_rank], weights['model 2'][layer_rank],\n",
    "                    biases['model 2'][layer_rank], x_validation, deep_layer_inputs, type='hidden representation', layer_rank=layer_rank)\n",
    "\n",
    "            else :\n",
    "                deep_layer_inputs = [layer_1, layer_2]\n",
    "                likelyhood[layer_rank]['preactivation'] = layers_covariances(\n",
    "                    weights['model 1'][layer_rank], biases['model 1'][layer_rank], weights['model 2'][layer_rank], \n",
    "                    biases['model 2'][layer_rank], x_validation, deep_layer_inputs, type='preactivation', layer_rank=layer_rank)[0]\n",
    "\n",
    "                likelyhood[layer_rank]['hidden'], layer_1, layer_2 = layers_covariances(\n",
    "                    weights['model 1'][layer_rank], biases['model 1'][layer_rank], weights['model 2'][layer_rank],\n",
    "                    biases['model 2'][layer_rank], x_validation, deep_layer_inputs, type='hidden', layer_rank=layer_rank)\n",
    "            \n",
    "        save_interval_size = likelyhood[1]['preactivation matrix'].shape[0]\n",
    "        # Register overlap information\n",
    "        for t in range (save_interval_size): \n",
    "            for layer_rank in overlap_dico['likelyhood_trajectory']['data'] :\n",
    "                for type_of_layer in overlap_dico['likelyhood_trajectory']['data'][layer_rank] :\n",
    "                    # First layer preactivation \n",
    "                    overlap_dico['likelyhood_trajectory']['data'][layer_rank][type_of_layer].append(likelyhood[layer_rank][type_of_layer][t].cpu())\n",
    "                    overlap_dico['likelyhood_variance_trajectory']['data'][layer_rank][type_of_layer].append((torch.sqrt((likelyhood[layer_rank][type_of_layer][t] - (likelyhood[layer_rank][type_of_layer][:].mean()))**2).mean()).cpu())\n",
    "    \n",
    "    # Plot datas\n",
    "    T = np.linspace(0, (min_time*save_interval_size+1)*10, min_time*save_interval_size+1)\n",
    "    for curve in overlap_dico :\n",
    "        legend_elements = []\n",
    "        for layer_rank in overlap_dico[curve]['data']:\n",
    "            for type_of_layer in overlap_dico[curve]['data'][layer_rank]:\n",
    "                plt.plot(T, overlap_dico[curve]['data'][layer_rank][type_of_layer], color=color_list[layer_rank][type_of_layer])\n",
    "                legend_elements += [Line2D([0], [0], color=color_list[layer_rank][type_of_layer], linewidth=5, label = label_list[layer_rank][type_of_layer])]                    \n",
    "        legend = plt.legend(handles=legend_elements, loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "        for handle in legend.legend_handles:\n",
    "            handle.set_markersize(15)\n",
    "        plt.title(overlap_dico[curve]['plot']['title'], pad=20)\n",
    "        plt.xlabel(overlap_dico[curve]['plot']['xlabel'])\n",
    "        plt.ylabel(overlap_dico[curve]['plot']['ylabel'])\n",
    "        # if curve == 'likelyhood_trajectory':\n",
    "        #     plt.ylim([-0.05,0.5])\n",
    "        plt.ylim(0,1.1)\n",
    "        plt.grid()\n",
    "        os.makedirs(save_path + '/' + architecture, exist_ok=True) \n",
    "        plt.savefig(save_path + '/' + architecture + '/' + curve + '.png', bbox_inches='tight')\n",
    "        plt.savefig(save_path + '/' + architecture + '/' + curve + '.svg', bbox_inches='tight')\n",
    "        plt.show()\n",
    "\n",
    "    return overlap_dico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def principal_angles_representation(activation_1, activation_2):\n",
    "    \"\"\"\n",
    "    Compare activations of two models via principal angles.\n",
    "\n",
    "    activation_1 : (N, d1) torch.Tensor\n",
    "    activation_2 : (N, d2) torch.Tensor\n",
    "\n",
    "    Returns:\n",
    "        angles_degrees : (min(d1, d2),) torch.Tensor\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # Move to CPU for QR decomposition\n",
    "    activation_1 = activation_1.cpu()\n",
    "    activation_2 = activation_2.cpu()\n",
    "\n",
    "    activation_1 = activation_1 - activation_1.mean(dim=0, keepdim=True)\n",
    "    activation_2 = activation_2 - activation_2.mean(dim=0, keepdim=True)\n",
    "    index = 0\n",
    "    for t in range(activation_1.shape[2]):\n",
    "        Q1, _ = torch.linalg.qr(activation_1[:,:,t])\n",
    "        Q2, _ = torch.linalg.qr(activation_2[:,:,t])\n",
    "\n",
    "        M = torch.matmul(Q1.T, Q2)\n",
    "        _, S, _ = torch.linalg.svd(M)\n",
    "\n",
    "        S = torch.clamp(S, -1.0, 1.0)\n",
    "        angles =  S #torch.arccos(S) * (180.0 / np.pi)\n",
    "        if index == 0 :\n",
    "            angles_tensor = angles.unsqueeze(1)\n",
    "        else: \n",
    "            angles_tensor = torch.cat([angles_tensor,angles.unsqueeze(1)], dim=1) \n",
    "        index+=1\n",
    "    return angles_tensor.to(device)\n",
    "\n",
    "\n",
    "def representation_overlap_trajectories(model_1, model_2, x_validation, save_path, architecture, add_to_title=''):\n",
    "    x_validation = x_validation.to(device)\n",
    "    min_time = np.min([len(model_1['layers trajectories'][1]), len(model_2['layers trajectories'][1])])\n",
    "    print(min_time)\n",
    "    \n",
    "    overlap_dico = {'normalized_cross_scalar_product_matrix_trace_trajectory' : \n",
    "        {'data' : {1 : {'preactivation' : [], 'hidden' : []}, 2 : {'preactivation' : [], 'hidden' : []}}, \n",
    "         'plot' : {'title' : 'Expectation of the cosine similarity between the representations\\nof ' + add_to_title,\n",
    "                   'xlabel' : 'Iteration N', 'ylabel' : r\"$\\mathbb{E}_{\\bf{x}}[\\cos(\\theta)]$\"}},\n",
    "                    'cross_scalar_product_matrix_trace_variance_trajectory' :\n",
    "        {'data' : {1 : {'preactivation' : [], 'hidden' : []}, 2 : {'preactivation' : [], 'hidden' : []}},\n",
    "         'plot' : {'title' : 'Variance of the cosine similarity between the representations\\nof ' + add_to_title,\n",
    "                   'xlabel' : 'Iteration N', 'ylabel' : r\"Var [$\\cos(\\theta)$]\"}},\n",
    "                    'arccos_product_matrix_trace_trajectory' :\n",
    "        {'data' : {1 : {'preactivation' : [], 'hidden' : []}, 2 : {'preactivation' : [], 'hidden' : []}},\n",
    "         'plot' : {'title' : 'Mean angle between the representations\\nof ' + add_to_title,\n",
    "                   'xlabel' : 'Iteration N', 'ylabel' : r\"$\\theta$\"}},\n",
    "                    'max_normalized_cross_scalar_product_matrix_trace_trajectory' :\n",
    "        {'data' : {1 : {'preactivation' : [], 'hidden' : []}, 2 : {'preactivation' : [], 'hidden' : []}},\n",
    "         'plot' : {'title' : 'Maximum cosine similarity between the representations\\n of ' + add_to_title,\n",
    "                   'xlabel' : 'Iteration N', 'ylabel' : r\"Max ($[\\cos(\\theta))$]\"}},\n",
    "                   'mean_prinicpal_angle_trajectory' : \n",
    "        {'data' : {1 : {'preactivation' : [], 'hidden' : []}, 2 : {'preactivation' : [], 'hidden' : []}}, \n",
    "         'plot' : {'title' : 'Principal angle between the representations\\nof ' + add_to_title,\n",
    "                   'xlabel' : 'Iteration N', 'ylabel' : r\"$\\mathbb{E}_{\\bf{x}}[\\cos(\\theta)]$\"}},\n",
    "                    'max_prinicpal_angle_trajectory' : \n",
    "        {'data' : {1 : {'preactivation' : [], 'hidden' : []}, 2 : {'preactivation' : [], 'hidden' : []}}, \n",
    "         'plot' : {'title' : 'Principal angle between the representations\\nof ' + add_to_title,\n",
    "                   'xlabel' : 'Iteration N', 'ylabel' : r\"$\\mathbb{E}_{\\bf{x}}[\\cos(\\theta)]$\"}}}\n",
    "\n",
    "    normalized_cross_scalar_product_matrix = {1 : {'preactivation' : [], 'hidden' : []}, 2 : {'preactivation' : [], 'hidden' : []}}\n",
    "    principal_angles_dico = {1 : {'preactivation' : [], 'hidden' : []}, 2 : {'preactivation' : [], 'hidden' : []}}\n",
    "    color_list = {1 : {'preactivation' : 'blue', 'hidden' : 'green'}, 2 : {'preactivation' : 'orange', 'hidden' : 'red'}}\n",
    "\n",
    "    label_list = {1 : {'preactivation' : r\"$(W_1.x^{\\top})^{\\top}.(W_1'.x^{\\top})$\", 'hidden' : r\"$(\\sigma(W_1.x^{\\top}))^{\\top}.(\\sigma(W_1'.x^{\\top}))$\"},\n",
    "                  2 : {'preactivation' : r\"$(W_2\\sigma(W_1.x^{\\top}))^{\\top}.(W_2'\\sigma(W_1'.x^{\\top}))$\", 'hidden' : r\"$(\\sigma(W_2\\sigma(W_1.x^{\\top})))^{\\top}.(\\sigma(W_2'\\sigma(W_1'.x^{\\top})))$\"}}\n",
    "    for first_layer_params_1, first_layer_params_2, second_layer_params_1, second_layer_params_2 in zip(model_1['layers trajectories'][1][:min_time],\n",
    "                                                                                                        model_2['layers trajectories'][1][:min_time], \n",
    "                                                                                                        model_1['layers trajectories'][2][:min_time],\n",
    "                                                                                                        model_2['layers trajectories'][2][:min_time]) :\n",
    "        \n",
    "        weights = {'model 1' : {1 : first_layer_params_1[:,:-1,:].to(device), 2 : second_layer_params_1[:,:-1,:].to(device)}, \n",
    "                   'model 2' : {1 : first_layer_params_2[:,:-1,:].to(device), 2 : second_layer_params_2[:,:-1,:].to(device)}}\n",
    "        biases = {'model 1' : {1 : first_layer_params_1[:,-1,:].to(device).unsqueeze(1), 2 : second_layer_params_1[:,-1,:].to(device).unsqueeze(1)}, \n",
    "                'model 2' : {1 : first_layer_params_2[:,-1,:].to(device).unsqueeze(1), 2 : second_layer_params_2[:,-1,:].to(device).unsqueeze(1)}}\n",
    "\n",
    "        for layer_rank in normalized_cross_scalar_product_matrix :\n",
    "            if layer_rank == 1:\n",
    "                deep_layer_inputs = []\n",
    "                normalized_cross_scalar_product_matrix[layer_rank]['preactivation'], layer_1, layer_2 = layer_representation(\n",
    "                    weights['model 1'][layer_rank], biases['model 1'][layer_rank], weights['model 2'][layer_rank], \n",
    "                    biases['model 2'][layer_rank], x_validation, deep_layer_inputs, type='preactivation', layer_rank=layer_rank)\n",
    "                principal_angles_dico[layer_rank]['preactivation'] = principal_angles_representation(layer_1, layer_2)\n",
    "\n",
    "                normalized_cross_scalar_product_matrix[layer_rank]['hidden'], layer_1, layer_2 = layer_representation(\n",
    "                    weights['model 1'][layer_rank], biases['model 1'][layer_rank], weights['model 2'][layer_rank],\n",
    "                    biases['model 2'][layer_rank], x_validation, deep_layer_inputs, type='hidden', layer_rank=layer_rank)\n",
    "                principal_angles_dico[layer_rank]['hidden'] = principal_angles_representation(layer_1, layer_2)\n",
    "\n",
    "            else :\n",
    "                deep_layer_inputs = [layer_1, layer_2]\n",
    "                normalized_cross_scalar_product_matrix[layer_rank]['preactivation'] = layer_representation(\n",
    "                    weights['model 1'][layer_rank], biases['model 1'][layer_rank], weights['model 2'][layer_rank], \n",
    "                    biases['model 2'][layer_rank], x_valid, deep_layer_inputs, type='preactivation', layer_rank=layer_rank)[0]\n",
    "                principal_angles_dico[layer_rank]['preactivation'] = principal_angles_representation(layer_1, layer_2)\n",
    "\n",
    "                normalized_cross_scalar_product_matrix[layer_rank]['hidden'], layer_1, layer_2 = layer_representation(\n",
    "                    weights['model 1'][layer_rank], biases['model 1'][layer_rank], weights['model 2'][layer_rank],\n",
    "                    biases['model 2'][layer_rank], x_valid, deep_layer_inputs, type='hidden', layer_rank=layer_rank)\n",
    "                principal_angles_dico[layer_rank]['hidden'] = principal_angles_representation(layer_1, layer_2)\n",
    "\n",
    "        save_interval_size = normalized_cross_scalar_product_matrix[layer_rank]['preactivation'].shape[2]\n",
    "        # Register overlap information\n",
    "        for t in range (save_interval_size): \n",
    "            for layer_rank in overlap_dico['normalized_cross_scalar_product_matrix_trace_trajectory']['data'] :\n",
    "                for type_of_layer in overlap_dico['normalized_cross_scalar_product_matrix_trace_trajectory']['data'][layer_rank] :\n",
    "                    # First layer preactivation \n",
    "                    overlap_dico['normalized_cross_scalar_product_matrix_trace_trajectory']['data'][layer_rank][type_of_layer].append(normalized_cross_scalar_product_matrix[layer_rank][type_of_layer][:,:,t].trace().cpu()/x_validation.shape[0])\n",
    "                    overlap_dico['max_normalized_cross_scalar_product_matrix_trace_trajectory']['data'][layer_rank][type_of_layer].append(normalized_cross_scalar_product_matrix[layer_rank][type_of_layer][:,:,t].max().cpu()) \n",
    "                    overlap_dico['arccos_product_matrix_trace_trajectory']['data'][layer_rank][type_of_layer].append((180/np.pi)*np.arccos(normalized_cross_scalar_product_matrix[layer_rank][type_of_layer][:,:,t].trace().cpu()/x_validation.shape[0]))\n",
    "                    overlap_dico['cross_scalar_product_matrix_trace_variance_trajectory']['data'][layer_rank][type_of_layer].append((torch.sqrt((normalized_cross_scalar_product_matrix[layer_rank][type_of_layer][:,:,t] - (normalized_cross_scalar_product_matrix[layer_rank][type_of_layer][:,:,t].trace()/x_validation.shape[0]))**2).mean()).cpu())\n",
    "                    overlap_dico['mean_prinicpal_angle_trajectory']['data'][layer_rank][type_of_layer].append(principal_angles_dico[layer_rank][type_of_layer].mean().cpu())\n",
    "                    overlap_dico['max_prinicpal_angle_trajectory']['data'][layer_rank][type_of_layer].append(principal_angles_dico[layer_rank][type_of_layer].max().cpu())\n",
    "\n",
    "    # Plot datas\n",
    "    \n",
    "    T = np.linspace(0, (min_time*save_interval_size+1)*10, min_time*save_interval_size+1)\n",
    "    for curve in overlap_dico :\n",
    "        legend_elements = []\n",
    "        for layer_rank in overlap_dico[curve]['data']:\n",
    "            for type_of_layer in overlap_dico[curve]['data'][layer_rank]:\n",
    "                plt.plot(T[:1000], overlap_dico[curve]['data'][layer_rank][type_of_layer][:1000], color=color_list[layer_rank][type_of_layer])\n",
    "                legend_elements += [Line2D([0], [0], color=color_list[layer_rank][type_of_layer], linewidth=5, label = label_list[layer_rank][type_of_layer])]                    \n",
    "        legend = plt.legend(handles=legend_elements, loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "        for handle in legend.legend_handles:\n",
    "            handle.set_markersize(15)\n",
    "        plt.title(overlap_dico[curve]['plot']['title'], pad=20)\n",
    "        plt.xlabel(overlap_dico[curve]['plot']['xlabel'])\n",
    "        plt.ylabel(overlap_dico[curve]['plot']['ylabel'])\n",
    "        if curve == 'normalized_cross_scalar_product_matrix_trace_trajectory' or curve == 'max_normalized_cross_scalar_product_matrix_trace_trajectory':\n",
    "            plt.ylim([-0.05,0.5])\n",
    "        elif curve == 'arccos_product_matrix_trace_trajectory':\n",
    "            plt.ylim([60,95])\n",
    "        elif curve == 'max_prinicpal_angle_trajectory':\n",
    "            plt.ylim([0.99,1.01])\n",
    "        plt.grid()\n",
    "        os.makedirs(save_path + '/' + architecture, exist_ok=True) \n",
    "        plt.savefig(save_path + '/' + architecture + '/' + curve + '.png', bbox_inches='tight')\n",
    "        plt.savefig(save_path + '/' + architecture + '/' + curve + '.svg', bbox_inches='tight')\n",
    "        plt.show()\n",
    "\n",
    "    return overlap_dico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_layer_representation(weight_1, bias_1, weight_2, bias_2, inputs, deep_layer_inputs, type, layer_rank):\n",
    "    if layer_rank==1 :\n",
    "        if type == 'preactivation':\n",
    "            layer_1 = torch.einsum('pdt,nd->pnt', weight_1, inputs) + bias_1\n",
    "            layer_2 = torch.einsum('pdt,nd->pnt', weight_2, inputs) + bias_2\n",
    "        elif type == 'hidden' :\n",
    "            layer_1 = torch.relu(torch.einsum('pdt,nd->pnt', weight_1, inputs) + bias_1)\n",
    "            layer_2 = torch.relu(torch.einsum('pdt,nd->pnt', weight_2, inputs) + bias_2)\n",
    "    else:\n",
    "        if type == 'preactivation':\n",
    "            layer_1 = torch.einsum('qpt,pnt->qnt', weight_1, deep_layer_inputs[0]) + bias_1\n",
    "            layer_2 = torch.einsum('qpt,pnt->qnt', weight_2, deep_layer_inputs[1]) + bias_2\n",
    "        elif type == 'hidden':\n",
    "            layer_1 = torch.relu(torch.einsum('qpt,pnt->qnt', weight_1, deep_layer_inputs[0]) + bias_1)\n",
    "            layer_2 = torch.relu(torch.einsum('qpt,pnt->qnt', weight_2, deep_layer_inputs[1]) + bias_2)\n",
    "    return layer_1, layer_2\n",
    "\n",
    "def preprocess_features(X):\n",
    "    X = X - X.mean(dim=0, keepdim=True)\n",
    "    X = X / (X.norm(dim=1, keepdim=True) + 1e-8)\n",
    "    return X\n",
    "\n",
    "def center_gram(K):\n",
    "    n = K.size(0)\n",
    "    unit = torch.ones_like(K) / n\n",
    "    return K - unit @ K - K @ unit + unit @ K @ unit\n",
    "\n",
    "def linear_CKA_torch(X, Y, eps=1e-8):\n",
    "    X = preprocess_features(X)\n",
    "    Y = preprocess_features(Y)\n",
    "    K = X @ X.T\n",
    "    L = Y @ Y.T\n",
    "    Kc = center_gram(K)\n",
    "    Lc = center_gram(L)\n",
    "    hsic = (Kc * Lc).sum()\n",
    "    norm_X = (Kc * Kc).sum().sqrt()\n",
    "    norm_Y = (Lc * Lc).sum().sqrt()\n",
    "    return hsic / (norm_X * norm_Y + eps)\n",
    "\n",
    "\n",
    "def representation_CKA_trajectories(model_1, model_2, x_validation, save_path, architecture, add_to_title=''):\n",
    "    x_validation = x_validation.to(device)\n",
    "    min_time = min(len(model_1['layers trajectories'][1]), len(model_2['layers trajectories'][1]))\n",
    "    print(f\"Number of checkpoints: {min_time}\")\n",
    "\n",
    "    # Output dictionary\n",
    "    cka_dico = {\n",
    "        'cka_trajectory': {\n",
    "            'data': {\n",
    "                1: {'preactivation': [], 'hidden': []},\n",
    "                2: {'preactivation': [], 'hidden': []}\n",
    "            },\n",
    "            'plot': {\n",
    "                'title': 'Linear CKA similarity between the representations\\nof ' + add_to_title,\n",
    "                'xlabel': 'Iteration N',\n",
    "                'ylabel': r\"CKA\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Color & label for plots\n",
    "    color_list = {\n",
    "        1: {'preactivation': 'blue', 'hidden': 'green'},\n",
    "        2: {'preactivation': 'orange', 'hidden': 'red'}\n",
    "    }\n",
    "    label_list = {\n",
    "        1: {'preactivation': r\"$\\text{Layer 1 Preactivation}$\", 'hidden': r\"$\\text{Layer 1 Hidden}$\"},\n",
    "        2: {'preactivation': r\"$\\text{Layer 2 Preactivation}$\", 'hidden': r\"$\\text{Layer 2 Hidden}$\"}\n",
    "    }\n",
    "\n",
    "    # Loop over checkpoints\n",
    "    for first_layer_params_1, first_layer_params_2, second_layer_params_1, second_layer_params_2 in zip(\n",
    "            model_1['layers trajectories'][1][:min_time],\n",
    "            model_2['layers trajectories'][1][:min_time],\n",
    "            model_1['layers trajectories'][2][:min_time],\n",
    "            model_2['layers trajectories'][2][:min_time]):\n",
    "\n",
    "        weights = {\n",
    "            'model 1': {1: first_layer_params_1[:, :-1, :].to(device), 2: second_layer_params_1[:, :-1, :].to(device)},\n",
    "            'model 2': {1: first_layer_params_2[:, :-1, :].to(device), 2: second_layer_params_2[:, :-1, :].to(device)}\n",
    "        }\n",
    "        biases = {\n",
    "            'model 1': {1: first_layer_params_1[:, -1, :].to(device).unsqueeze(1), 2: second_layer_params_1[:, -1, :].to(device).unsqueeze(1)},\n",
    "            'model 2': {1: first_layer_params_2[:, -1, :].to(device).unsqueeze(1), 2: second_layer_params_2[:, -1, :].to(device).unsqueeze(1)}\n",
    "        }\n",
    "\n",
    "        layer_representations = {1: {}, 2: {}}\n",
    "\n",
    "        # First layer\n",
    "        deep_layer_inputs = []\n",
    "        for rep_type in ['preactivation', 'hidden']:\n",
    "            rep_1, rep_2 = extract_layer_representation(\n",
    "                weights['model 1'][1], biases['model 1'][1],\n",
    "                weights['model 2'][1], biases['model 2'][1],\n",
    "                x_validation, deep_layer_inputs, rep_type, layer_rank=1\n",
    "            )\n",
    "            # Collapse across feature dimension: (d, n, t) -> (n, d * t)\n",
    "            rep_1_flat = rep_1.permute(1, 0, 2).reshape(rep_1.shape[1], -1)\n",
    "            rep_2_flat = rep_2.permute(1, 0, 2).reshape(rep_2.shape[1], -1)\n",
    "            cka_score = linear_CKA_torch(rep_1_flat, rep_2_flat)\n",
    "            cka_dico['cka_trajectory']['data'][1][rep_type].append(cka_score.cpu())\n",
    "\n",
    "        # Cache for second layer\n",
    "        deep_layer_inputs = [rep_1, rep_2]\n",
    "\n",
    "        # Second layer\n",
    "        for rep_type in ['preactivation', 'hidden']:\n",
    "            rep_1, rep_2 = extract_layer_representation(\n",
    "                weights['model 1'][2], biases['model 1'][2],\n",
    "                weights['model 2'][2], biases['model 2'][2],\n",
    "                x_validation, deep_layer_inputs, rep_type, layer_rank=2\n",
    "            )\n",
    "            rep_1_flat = rep_1.permute(1, 0, 2).reshape(rep_1.shape[1], -1)\n",
    "            rep_2_flat = rep_2.permute(1, 0, 2).reshape(rep_2.shape[1], -1)\n",
    "            cka_score = linear_CKA_torch(rep_1_flat, rep_2_flat)\n",
    "            cka_dico['cka_trajectory']['data'][2][rep_type].append(cka_score.cpu())\n",
    "\n",
    "    # Plotting\n",
    "    T = torch.arange(min_time).float() * 10\n",
    "    for curve in cka_dico:\n",
    "        legend_elements = []\n",
    "        for layer_rank in cka_dico[curve]['data']:\n",
    "            for rep_type in cka_dico[curve]['data'][layer_rank]:\n",
    "                plt.plot(T, cka_dico[curve]['data'][layer_rank][rep_type], color=color_list[layer_rank][rep_type])\n",
    "                legend_elements += [Line2D([0], [0], color=color_list[layer_rank][rep_type], linewidth=5, label=label_list[layer_rank][rep_type])]\n",
    "        legend = plt.legend(handles=legend_elements, loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "        for handle in legend.legend_handles:\n",
    "            handle.set_markersize(15)\n",
    "        plt.title(cka_dico[curve]['plot']['title'], pad=20)\n",
    "        plt.xlabel(cka_dico[curve]['plot']['xlabel'])\n",
    "        plt.ylabel(cka_dico[curve]['plot']['ylabel'])\n",
    "        plt.ylim([0, 1.05])\n",
    "        plt.grid()\n",
    "        os.makedirs(f\"{save_path}/{architecture}\", exist_ok=True)\n",
    "        plt.savefig(f\"{save_path}/{architecture}/{curve}.png\", bbox_inches='tight')\n",
    "        plt.savefig(f\"{save_path}/{architecture}/{curve}.svg\", bbox_inches='tight')\n",
    "        plt.show()\n",
    "\n",
    "    return cka_dico\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_decomposition import CCA\n",
    "\n",
    "# def extract_layer_representation(weight_1, bias_1, weight_2, bias_2, inputs, deep_layer_inputs, rep_type, layer_rank):\n",
    "#     if layer_rank == 1:\n",
    "#         if rep_type == 'preactivation':\n",
    "#             layer_1 = torch.einsum('pdt,nd->pnt', weight_1, inputs) + bias_1\n",
    "#             layer_2 = torch.einsum('pdt,nd->pnt', weight_2, inputs) + bias_2\n",
    "#         else:  # hidden\n",
    "#             layer_1 = torch.relu(torch.einsum('pdt,nd->pnt', weight_1, inputs) + bias_1)\n",
    "#             layer_2 = torch.relu(torch.einsum('pdt,nd->pnt', weight_2, inputs) + bias_2)\n",
    "#     else:\n",
    "#         if rep_type == 'preactivation':\n",
    "#             layer_1 = torch.einsum('qpt,pnt->qnt', weight_1, deep_layer_inputs[0]) + bias_1\n",
    "#             layer_2 = torch.einsum('qpt,pnt->qnt', weight_2, deep_layer_inputs[1]) + bias_2\n",
    "#         else:  # hidden\n",
    "#             layer_1 = torch.relu(torch.einsum('qpt,pnt->qnt', weight_1, deep_layer_inputs[0]) + bias_1)\n",
    "#             layer_2 = torch.relu(torch.einsum('qpt,pnt->qnt', weight_2, deep_layer_inputs[1]) + bias_2)\n",
    "#     return layer_1, layer_2\n",
    "\n",
    "def extract_layer_representation(weight_1, bias_1, weight_2, bias_2, inputs, deep_layer_inputs, rep_type, layer_rank):\n",
    "    if layer_rank == 1:\n",
    "        if rep_type == 'preactivation':\n",
    "            layer_1 = torch.einsum('pdt,nd->pnt', weight_1, inputs[0]) + bias_1\n",
    "            layer_2 = torch.einsum('pdt,nd->pnt', weight_2, inputs[1]) + bias_2\n",
    "        else:  # hidden\n",
    "            layer_1 = torch.relu(torch.einsum('pdt,nd->pnt', weight_1, inputs[0]) + bias_1)\n",
    "            layer_2 = torch.relu(torch.einsum('pdt,nd->pnt', weight_2, inputs[1]) + bias_2)\n",
    "    else:\n",
    "        if rep_type == 'preactivation':\n",
    "            layer_1 = torch.einsum('qpt,pnt->qnt', weight_1, deep_layer_inputs[0]) + bias_1\n",
    "            layer_2 = torch.einsum('qpt,pnt->qnt', weight_2, deep_layer_inputs[1]) + bias_2\n",
    "        else:  # hidden\n",
    "            layer_1 = torch.relu(torch.einsum('qpt,pnt->qnt', weight_1, deep_layer_inputs[0]) + bias_1)\n",
    "            layer_2 = torch.relu(torch.einsum('qpt,pnt->qnt', weight_2, deep_layer_inputs[1]) + bias_2)\n",
    "    return layer_1, layer_2\n",
    "\n",
    "def preprocess_features(X):\n",
    "    X = X - X.mean(dim=0, keepdim=True)\n",
    "    norm = X.norm(dim=1, keepdim=True) + 1e-8\n",
    "    X = X / norm\n",
    "    X[torch.isnan(X)] = 0\n",
    "    X[torch.isinf(X)] = 0\n",
    "    return X\n",
    "\n",
    "def svd_reduction(X, k):\n",
    "    # Check pour NaNs ou infs avant SVD\n",
    "    if torch.isnan(X).any() or torch.isinf(X).any():\n",
    "        print(\"⚠️ SVD impossible: NaNs ou infs détectés dans la matrice\")\n",
    "        print(X)\n",
    "        return torch.zeros((X.shape[0], min(k, X.shape[0])), device=X.device)\n",
    "    \n",
    "    # Vérifie que X n'est pas dégénéré\n",
    "    if X.shape[0] == 0 or X.shape[1] == 0:\n",
    "        print(f\"⚠️ SVD impossible: X a une forme nulle {X.shape}\")\n",
    "        return torch.zeros((X.shape[0], 0), device=X.device)\n",
    "    \n",
    "    # Ajuste k si nécessaire\n",
    "    k_eff = min(k, X.shape[0], X.shape[1])\n",
    "    if k_eff == 0:\n",
    "        return torch.zeros((X.shape[0], 0), device=X.device)\n",
    "    \n",
    "    try:\n",
    "        U, S, Vh = torch.linalg.svd(X, full_matrices=False)\n",
    "        return U[:, :k_eff] * S[:k_eff]\n",
    "    except RuntimeError as e:\n",
    "        print(f\"⚠️ SVD failed with error: {e}\")\n",
    "        print(\"Matrix shape:\", X.shape)\n",
    "        return torch.zeros((X.shape[0], k_eff), device=X.device)\n",
    "\n",
    "def compute_cca_similarity(X, Y, k=20):\n",
    "    X = preprocess_features(X)\n",
    "    Y = preprocess_features(Y)\n",
    "    \n",
    "    if torch.isnan(X).any() or torch.isinf(X).any() or torch.isnan(Y).any() or torch.isinf(Y).any():\n",
    "        print(\"⚠️ NaNs ou infs détectés après preprocessing.\")\n",
    "        return 0.0\n",
    "\n",
    "    X_red = svd_reduction(X.cpu(), k)\n",
    "    Y_red = svd_reduction(Y.cpu(), k)\n",
    "\n",
    "    if X_red.shape[1] == 0 or Y_red.shape[1] == 0:\n",
    "        print(\"⚠️ Empty reduced representations after SVD\")\n",
    "        return 0.0\n",
    "\n",
    "    n_components = min(X_red.shape[1], Y_red.shape[1], k)\n",
    "    if n_components == 0:\n",
    "        return 0.0\n",
    "\n",
    "    cca = CCA(n_components=n_components, max_iter=5000, tol=1e-4)\n",
    "    try:\n",
    "        X_c, Y_c = cca.fit_transform(X_red.cpu().numpy(), Y_red.cpu().numpy())\n",
    "        corr = np.corrcoef(X_c.T, Y_c.T).diagonal(offset=X_c.shape[1])\n",
    "        return np.mean(corr)\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Sklearn CCA failed: {e}\")\n",
    "        return 0.0\n",
    "\n",
    "\n",
    "def representation_SVCCA_trajectories(model_1, model_2, x_validation, save_path, architecture, add_to_title='', svd_dim=20):\n",
    "    x_validation = [x.to(device) for x in x_validation]\n",
    "    min_time = min(len(model_1['layers trajectories'][1]), len(model_2['layers trajectories'][1]))\n",
    "    print(f\"Number of checkpoints: {min_time}\")\n",
    "\n",
    "    svcca_dico = {\n",
    "        'svcca_trajectory': {\n",
    "            'data': {\n",
    "                1: {'preactivation': [], 'hidden': []},\n",
    "                2: {'preactivation': [], 'hidden': []}\n",
    "            },\n",
    "            'plot': {\n",
    "                'title': 'SVCCA similarity between the representations\\nof ' + add_to_title,\n",
    "                'xlabel': 'Iteration N',\n",
    "                'ylabel': 'SVCCA'\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    color_list = {\n",
    "        1: {'preactivation': 'blue', 'hidden': 'green'},\n",
    "        2: {'preactivation': 'orange', 'hidden': 'red'}\n",
    "    }\n",
    "    label_list = {\n",
    "        1: {'preactivation': r\"$\\text{Layer 1 Preactivation}$\", 'hidden': r\"$\\text{Layer 1 Hidden}$\"},\n",
    "        2: {'preactivation': r\"$\\text{Layer 2 Preactivation}$\", 'hidden': r\"$\\text{Layer 2 Hidden}$\"}\n",
    "    }\n",
    "\n",
    "    for first_layer_params_1, first_layer_params_2, second_layer_params_1, second_layer_params_2 in zip(\n",
    "        model_1['layers trajectories'][1][:min_time],\n",
    "        model_2['layers trajectories'][1][:min_time],\n",
    "        model_1['layers trajectories'][2][:min_time],\n",
    "        model_2['layers trajectories'][2][:min_time]):\n",
    "\n",
    "        weights = {\n",
    "            'model 1': {1: first_layer_params_1[:, :-1, :].to(device), 2: second_layer_params_1[:, :-1, :].to(device)},\n",
    "            'model 2': {1: first_layer_params_2[:, :-1, :].to(device), 2: second_layer_params_2[:, :-1, :].to(device)}\n",
    "        }\n",
    "        biases = {\n",
    "            'model 1': {1: first_layer_params_1[:, -1, :].to(device).unsqueeze(1), 2: second_layer_params_1[:, -1, :].to(device).unsqueeze(1)},\n",
    "            'model 2': {1: first_layer_params_2[:, -1, :].to(device).unsqueeze(1), 2: second_layer_params_2[:, -1, :].to(device).unsqueeze(1)}\n",
    "        }\n",
    "\n",
    "        layer_representations = {1: {}, 2: {}}\n",
    "\n",
    "        deep_layer_inputs = []\n",
    "        for rep_type in ['preactivation', 'hidden']:\n",
    "            rep_1, rep_2 = extract_layer_representation(\n",
    "                weights['model 1'][1], biases['model 1'][1],\n",
    "                weights['model 2'][1], biases['model 2'][1],\n",
    "                x_validation, deep_layer_inputs, rep_type, layer_rank=1\n",
    "            )\n",
    "            rep_1_flat = rep_1.permute(1, 0, 2).reshape(rep_1.shape[1], -1)\n",
    "            rep_2_flat = rep_2.permute(1, 0, 2).reshape(rep_2.shape[1], -1)\n",
    "            svcca_score = compute_cca_similarity(rep_1_flat, rep_2_flat, k=svd_dim)\n",
    "            svcca_dico['svcca_trajectory']['data'][1][rep_type].append(svcca_score)\n",
    "        deep_layer_inputs = [rep_1, rep_2]\n",
    "\n",
    "        for rep_type in ['preactivation', 'hidden']:\n",
    "            rep_1, rep_2 = extract_layer_representation(\n",
    "                weights['model 1'][2], biases['model 1'][2],\n",
    "                weights['model 2'][2], biases['model 2'][2],\n",
    "                x_validation, deep_layer_inputs, rep_type, layer_rank=2\n",
    "            )\n",
    "            rep_1_flat = rep_1.permute(1, 0, 2).reshape(rep_1.shape[1], -1)\n",
    "            rep_2_flat = rep_2.permute(1, 0, 2).reshape(rep_2.shape[1], -1)\n",
    "            svcca_score = compute_cca_similarity(rep_1_flat, rep_2_flat, k=svd_dim)\n",
    "            svcca_dico['svcca_trajectory']['data'][2][rep_type].append(svcca_score)\n",
    "\n",
    "    T = torch.arange(min_time).float() * 10\n",
    "    for curve in svcca_dico:\n",
    "        legend_elements = []\n",
    "        for layer_rank in svcca_dico[curve]['data']:\n",
    "            for rep_type in svcca_dico[curve]['data'][layer_rank]:\n",
    "                plt.plot(T, svcca_dico[curve]['data'][layer_rank][rep_type], color=color_list[layer_rank][rep_type])\n",
    "                legend_elements += [Line2D([0], [0], color=color_list[layer_rank][rep_type], linewidth=5, label=label_list[layer_rank][rep_type])]\n",
    "        legend = plt.legend(handles=legend_elements, loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "        for handle in legend.legend_handles:\n",
    "            handle.set_markersize(15)\n",
    "        plt.title(svcca_dico[curve]['plot']['title'], pad=20)\n",
    "        plt.xlabel(svcca_dico[curve]['plot']['xlabel'])\n",
    "        plt.ylabel(svcca_dico[curve]['plot']['ylabel'])\n",
    "        plt.ylim([0, 1.05])\n",
    "        plt.grid()\n",
    "        os.makedirs(f\"{save_path}/{architecture}\", exist_ok=True)\n",
    "        plt.savefig(f\"{save_path}/{architecture}/{curve}.png\", bbox_inches='tight')\n",
    "        plt.savefig(f\"{save_path}/{architecture}/{curve}.svg\", bbox_inches='tight')\n",
    "        plt.show()\n",
    "\n",
    "    return svcca_dico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of checkpoints: 5\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'svcca_trajectory': {'data': {1: {'preactivation': [np.float64(0.05105568844684322),\n",
       "     np.float64(0.05049781807192526),\n",
       "     np.float64(0.05269358032967586),\n",
       "     np.float64(0.05323015759607871),\n",
       "     np.float64(0.05321780981465372)],\n",
       "    'hidden': [np.float64(0.0523370616130324),\n",
       "     np.float64(0.051266635362064085),\n",
       "     np.float64(0.050860386412859136),\n",
       "     np.float64(0.051167269779813083),\n",
       "     np.float64(0.051445646395246444)]},\n",
       "   2: {'preactivation': [np.float64(0.053573128758651424),\n",
       "     np.float64(0.05430939381499391),\n",
       "     np.float64(0.05455396460818248),\n",
       "     np.float64(0.054220954646785904),\n",
       "     np.float64(0.05402885435299577)],\n",
       "    'hidden': [np.float64(0.05156155819457174),\n",
       "     np.float64(0.052412383194906174),\n",
       "     np.float64(0.053499180710600225),\n",
       "     np.float64(0.05357418131730385),\n",
       "     np.float64(0.053690604016445084)]}},\n",
       "  'plot': {'title': 'SVCCA similarity between the representations\\nof  two fully trained networks',\n",
       "   'xlabel': 'Iteration N',\n",
       "   'ylabel': 'SVCCA'}}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### 08/07 - Correlations between representations on CIFAR-10 : car-plane #####\n",
    "\n",
    "\n",
    "\n",
    "date = '16_07_25'\n",
    "\n",
    "dataset = 'teacher_(d-81_k-1_n-10e5)'\n",
    "\n",
    "save_path = 'Post-processing/15_07_25/'\n",
    "save_path_convergence_speed = save_path + 'Convergence speed/Dataset_' + dataset + '_statistical_results/'\n",
    "save_path_normalized_convergence_speed = save_path + 'Normalized convergence speed/Dataset_' + dataset + '_statistical_results/'\n",
    "save_path_max_accuracy = save_path + 'Maximum accuracy/Dataset_' + dataset + '_statistical_results/'\n",
    "save_path_accuracy_trajectory = save_path + 'Accuracy trajectory/Dataset_' + dataset + '_statistical_results/'\n",
    "save_path_loss_trajectory = save_path + 'Loss trajectory/Dataset_' + dataset + '_statistical_results/'\n",
    "save_path_overlap = save_path + 'Overlaps/Dataset_' + dataset + '/'\n",
    "save_path_covariances = save_path + 'Covariances/Dataset_' + dataset + '/'\n",
    "\n",
    "\n",
    "os.makedirs(save_path_convergence_speed, exist_ok=True)\n",
    "os.makedirs(save_path_normalized_convergence_speed, exist_ok=True)\n",
    "os.makedirs(save_path_max_accuracy, exist_ok=True)\n",
    "os.makedirs(save_path_accuracy_trajectory, exist_ok=True)\n",
    "os.makedirs(save_path_loss_trajectory, exist_ok=True)\n",
    "os.makedirs(save_path_overlap, exist_ok=True)\n",
    "os.makedirs(save_path_covariances, exist_ok=True)\n",
    "\n",
    "\n",
    "model_ref_1 = load_data_dictionnary(dataset + \"_torch_model_(81+784.2+1)\" + '_fully_trained_1', date)\n",
    "model_ref_2 = load_data_dictionnary(dataset + \"_torch_model_(81+784.2+1)\" + '_fully_trained_2', date)\n",
    "x_train = torch.load('Classifiers/' + date + '/' + date + '_' + dataset + '_torch_model_(81+784.2+1)_fully_trained_1/training_set.pt')\n",
    "x_valid = torch.load('Classifiers/' + date + '/' + date + '_' + dataset + '_torch_model_(81+784.2+1)_fully_trained_1/validation_set.pt')\n",
    "\n",
    "representation_SVCCA_trajectories(model_ref_1, model_ref_2, [x_valid[:5000], x_valid[5000:10000]], save_path=save_path_overlap, architecture='(81+784.2+1)', add_to_title=' two fully trained networks')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
